De la ligne à la note : croisements entre sténographie, informatique & notation musicale au xxie siècle

École nationale supérieure des beaux-arts de Paris
Mémoire de diplôme sous la direction de pascal rousseau
2021


« La musique n’est pas une langue. Toute pièce musicale est comme un rocher de forme complexe avec des stries et des dessins gravés dessus et dedans que les hommes peuvent déchiffrer de mille manières sans qu’aucune soit la meilleure ou la plus vraie. »

Iannis Xenakis, Le Diatope, Geste de lumière et de son.
Paris, Centre Georges Pompidou, 1978, p. 7. 1

« Caro Pratella, io sottopongo al tuo genio futurista queste mie constatazioni, invitandoti alla discussione. Non sono musicista; non ho dunque predilezioni acustiche, né opere da difendere. Sono un pittore futurista che proietta fuori di sé in un’arte molto amata la sua volontà di rinnovare tutto. Perciò più temerario di quanto potrebbe esserlo un musicista di professione, non preoccupandomi della mia apparente incompetenza e convinto che l’audacia abbia tutti i diritti e tutte le possibilità, ho potuto intuire il grande rinnovamento della musica mediante l’Arte dei Rumori. »

Luigi Russolo, « L’Arte dei rumori », I Manifesti del
futurismo. Florence, Lacerba, 1914. p. 132.


Présentation

La communication est une brique de base des sociétés humaines. L’écriture est inscrite au cœur de cette brique. Aujourd’hui, la quasi-totalité des textes récents existe grâce aux supports numériques et à travers eux. Ce n’était pas le cas jusqu’à encore récemment ; les progrès technologiques et en particulier la mécanisation de notre rapport au texte sont à l’origine de ce changement de paradigme. Comment était-il possible de prendre en note la parole, d’archiver les discours, avant l’invention de la machine à écrire, avant celle du phonographe ? La principale réponse à cette question tient en un mot : sténographie, ou plus vulgairement, « l’art d’écrire aussi vite que la parole ».
La sténographie englobe tout un pan des technologies de l’écriture qui a presque complètement disparu du monde de l’administration au début du xxie siècle. Notre recherche a débuté alors que nous nous intéressions aux langues construites et aux alternatives à l’orthographe. Nous découvrions alors, intrigué, tout un monde graphique dont nous ignorions complètement l’existence et qui redirigeait presque à chaque fois vers la notion de sténographie ; des systèmes d’écriture phonétiques et non alphabétiques permettant d’écrire plus rapidement que d’ordinaire. Plus nous avancions dans cette recherche et plus s’imposait à nous le sentiment de n’avoir accès qu’à la partie émergée d’un immense iceberg. La sténographie, en sa qualité d’« écriture », n’a ipso facto pas sa place dans notre monde numérique. Pour cerner correctement cet objet, la seule alternative reste les livres, mais même ici, la tâche se révéla ardue : très peu d’ouvrages scientifiques récents ont été publiés sur le sujet. Paradoxalement, de cette difficulté à satisfaire notre curiosité naquit un intérêt croissant à élucider une question : est-ce que la sténographie aurait encore un rôle à jouer dans la société contemporaine ?
Pour répondre à cette question, nous devons aller à l’encontre des approches proposées par les derniers sténographes, trop souvent unis dans un même refus de la modernité. La voie que nous décidons d’emprunter ici n’a, à notre connaissance, jamais été considérée : nous souhaitons penser la sténographie à la lumière des technologies, non pas dans un esprit d’opposition anti-moderniste, non pas en considérant les technologies contemporaines comme ennemies, mais en imaginant en quoi la sténographie pourrait entrer en synergie avec ces dernières, ou venir les compléter là où elles sont les moins efficientes.
Le titre De la ligne à la note se veut polysémique : la « note » est omniprésente dans nos sociétés de l’écrit, qu’elle soit de bas de page, manuscrite, musicale, personnelle, ou encore tironienne. Comme le fait remarquer John Haines, le mot latin nota (dérivé du latin nosco, apprendre, connaître) est étroitement lié au concept de mémoire. La note est, dans les cultures de l’écrit, le tout premier degré de la connaissance, et agit comme une clé pour accéder à nos savoirs. Nous considérerons ici la note dans toutes ses dimensions sémantiques, en accordant un intérêt plus appuyé à la note manuscrite et à la note de musique. Ce dernier type d’inscription, la note musicale, figurera au centre de notre réflexion, et la musique sera le principal domaine d’application de nos hypothèses. En effet, si la sténographie est d’abord connue comme étant une méthode de scripturalisation de l’oral, c’est-à-dire de mise en écriture, elle n’en est pas moins une technologie de scripturalisation tout court, et peut théoriquement transcrire n’importe quelle sorte de phénomène – dont la musique. Au même titre que la sténographie est succinctement décrite comme l’« art d’écrire aussi vite que la parole », la sténographie musicale est l’« art d’écrire au rythme de la musique ».
Ainsi, le but de ce mémoire n’est pas de retracer une histoire exhaustive de la sténographie, quand bien même nous nous attacherons à l’étude de son passé pour en comprendre les tenants et les aboutissants. Ce mémoire n’a pas non plus pour vocation de proposer d’un énième système sténographique se voulant meilleur que les précédents ; nous n’avons pas la prétention de pouvoir améliorer ceux qui existent déjà. Nous chercherons à établir ici une base conceptuelle à partir de laquelle vérifier des hypothèses. Ce travail est un mémoire de recherche-création, et ne se suffit pas à lui-même. La volonté qui en a motivé la rédaction s’inscrit dans le cadre plus vaste d’une mise en œuvre plastique dont les idées seront ici exposées. En retour, nous espérons que la réalisation formelle de ces travaux pourra nourrir la présente étude théorique, en valider certaines hypothèses et en infirmer d’autres.
Nous avons organisé ce mémoire en deux parties. La première vise principalement à définir un contexte lexicologique et historique afin de circonscrire l’objet d’étude que constitue la sténographie. Dans un premier temps, nous proposerons une série de définitions quant aux notions d’écriture et de sténographie. Puis, nous décrirons les propriétés communes à la plupart des systèmes sténographiques, aussi bien sur le plan linguistique que sur le plan graphique. À partir des ces quelques prolégomènes, nous pourrons entrer sans mal dans un survol de l’histoire de la sténographie de la parole. Nous tenterons d’évoquer toutes les grandes étapes qui structurèrent cette science de l’Antiquité à nos jours, en faisant progresser crescendo la densité d’information jusqu’à la seconde moitié du xxe siècle, période crépusculaire pour la sténographie. À chaque fois, nous essaierons de comprendre le rôle que tenait la sténographie au sein de la société dans laquelle elle était utilisée, et quelles étaient les intentions des différents inventeurs de ces systèmes. Nous appliquerons ensuite cette même structure à la sténographie musicale : nous verrons dans quel contexte les systèmes de sténographie musicale ont été développés, quelle étaient la place qu’ils occupaient vis-à-vis du solfège, et quels sont les liens qu’ils entretiennent avec la sténographie de la parole.
Cette entrée en matière, relevant essentiellement de l’histoire des techniques, permet d’aborder la seconde partie de notre mémoire, qui se veut plus expérimentale. En amont de la rédaction de ce texte, nous envisagions de réhabilitater de la sténographie essentiellement en tant que technologie de transcription immédiate de la parole. Au cours de nos recherches, nous avons aussi exploré d’autres angles d’approche comme notamment la cryptographie, mais c’est finalement la musique que nous retiendrons comme domaine d’application privilégié de la sténographie aujourd’hui.
Ainsi, il s’agira, dans la seconde partie de cette étude, de comprendre ce qu’englobent les notions de partition et de notation musicale afin de les mettre en regard avec la sténographie musicale. Nous étudierons ensuite quelques exemples de systèmes notationnels dans la musique expérimentale du xxe siècle, qui a alors tenté de s’émanciper du solfège. Puis, nous verrons en quoi la sténographie pourrait venir compléter le système solfégique dans la prise de note de la musique, mais aussi dans une relation tout à fait différente à la musique, qui se rapporterait à la composition en temps réel. Cette idée, que nous développerons en partie II.b.2.ii., se situe à mi-chemin entre les concepts de partition animée et de partition en temps réel. Pour bien expliciter notre thèse, nous commencerons par reprendre les fondements historiques de la musique expérimentale du xxie siècle, à savoir le contexte d’innovation technologique du milieu du xxe siècle – en insistant sur l’histoire de l’upic, machine inventée et portée par Iannis Xenakis. Ensuite, nous dresserons un état de l’art des logiciels pouvant être associés à la notation musicale non solfégique au xxie siècle. Ces derniers éléments contextuels nous permettront d’enfin aborder les avantages de la sténographie, aussi bien en musique qu’au quotidien. Nous verrons en quoi son caractère ésotérique peut nous amener à de nouvelles approches créatives, et comment cette technologie questionne, entre autres, nos rapports au temps, à la langue, aux technologies et à la pédagogie.
Il convient maintenant d’évoquer nos sources. Nous allons le voir, il existe une myriade de systèmes sténographiques, aussi bien pour la sténographie de la parole que pour celle de la musique. Cependant, comme mentionné plus haut, ces savoirs deviennent de plus en plus difficiles d’accès ; la sténographie n’a pas été pensée pour les supports numériques, ce qui la rend presque totalement absente d’Internet. En ce qui concerne les ouvrages spécifiquement sur la sténographie, la majorité de nos sources provient des bibliothèques parisiennes, principalement la Bibliothèque nationale de France (sites François Mitterrand et Richelieu-Louvois) et la Bibliothèque de l’Institut national d’histoire de l’art (inha). La plupart des ouvrages consultés sont des sources primaires, à savoir des manuels d’apprentissage de systèmes sténographiques particuliers. Il existe quelques sources secondaires, mais la sténographie est un objet d’étude relativement peu prisé des sciences humaines. La majorité de ces ouvrages est présente uniquement sur un seul site, n’est pas consultable en ligne, et nécessite ainsi de pouvoir se rendre dans ces bibliothèques. En d’autres termes, ce travail de recherche n’aurait pas été possible s’il n’avait pas été mené à Paris. La seconde partie, plus contemporaine, est très largement basée sur des ouvrages plus généralistes, grand public, et édités il y a moins d’un siècle. Beaucoup de nos sources proviennent aussi d’Internet, en particulier celles concernant l’informatique musicale.
Nos recherches sur la sténographie ont aussi été entravées par une confusion récurrente, pouvant sembler anecdotique, mais qui au final est trop prégnante pour être omise. Nombre d’auteurs confondent le terme sténographie avec le terme stéganographie. La stéganographie, du grec ancien στεγανός (steganos, couvrir), est un sous-domaine de la cryptographie relatif aux méthodes de dissimulation des messages. La stéganographie permet de cacher des informations. Cette confusion se manifeste sous la forme d’une utilisation interchangeable des deux mots, aussi bien dans des ouvrages réputés sérieux que dans des revues prétendument révisées par les pairs. La sténographie, nous le verrons, revient régulièrement dans les discussions sur la cryptographie, mais n’est généralement pas associée à la stéganographie.
Toutes ces contraintes présagent d’autant plus d’une disparition totale de la sténographie et des savoirs qui lui sont associés. En plus de nos objectifs de recherche-création, ce mémoire a été rédigé dans une optique de conservation de ces savoirs. Nous n’allons pas ici nous attarder sur la manière dont les connaissances doivent être archivées, transmises dans le temps et diffusées. Nous souhaitons simplement rendre hommage ici à cette facette de notre histoire écrite, qui façonna notre société actuelle et qui occupait le quotidien de millions de personnes jusqu’à encore récemment, mais qui semble aujourd’hui sur le point de quitter totalement notre imaginaire collectif.
Nous conclurons cette introduction avec la figure 1 située sur la double page suivante. Il s’agit d’une prise de vue du premier « atelier découverte » de la sténographie, que nous avons organisé le 15 octobre 2021 aux Beaux-Arts de Paris. Cet évènement, qui se déroula en présence d’une quinzaine de participants, constitua le premier acte d’une série de manifestations durant lesquelles nous partageons notre expérience de ces systèmes d’écriture. Lors de ce premier atelier, les participants montrèrent un réel intérêt pour la sténographie Duployé, une curiosité naturelle et une forme d’amusement à essayer de composer leurs premiers sténogrammes. Leurs retours renforcent nos convictions quant au potentiel social et pédagogique de la sténographie.


Première partie : Histoire de la sténographie en europe

a. Qu’est-ce que la sténographie ?

Afin de cerner ce qu’est la sténographie, il convient en premier lieu de définir la notion d’écriture, et plus précisément la notion d’écriture manuscrite, dont il sera principalement sujet dans cette étude. Albert Navarre (1874-1955), l’une de nos références principales concernant l’histoire de la sténographie, s’y essaye de la manière suivante :

« L’écriture est l’art de fixer la parole par des signes conventionnels, tracés à la main, qu’on appelle caractères. »

Navarre a raison de préciser qu’il s’agit de « signes conventionnels ». En effet, sans cette qualification, n’importe quel dessin pourrait être qualifié d’écriture. Un système d’écriture invoque le besoin d’une structure, d’une grammaire. Cette définition comporte cependant une faille : l’écriture ne permet pas uniquement de transcrire la parole, mais nous autorise à plus que cela. Cette omission sert le propos introductif de Navarre quant à la sténographie, qu’il aborde uniquement comme étant un outil de la prise de note. Cependant, pour nombre d’auteurs, la définition de l’écriture est plus large : elle est souvent qualifiée de technologie de communication, une somme de connaissances techniques. Dans cette idée, Walter Ong (1912-2003), la range à la même place que d’autres technologies du même ordre telles que le discours, l’imprimé, l’écran et l’ordinateur. Cette définition, moins centrée sur les langues et l’oralité, permet d’inclure dans la notion d’écriture les langues non verbales (e.g. les langues sifflées ou les langues des signes), ou encore la musique. Ici, ce qui nous intéressera avec l’écriture est son rapport au corps et au mouvement, une dimension des technologies de communication qui a énormément évolué depuis la révolution industrielle. Cette évolution s’est retranscrite dans la langue française ; de plus en plus, l’usage s’éloigne du sens originel du préfixe -graphie (du grec ancien γράφειν, graphein, écrire) pour tendre vers une importance accrue du préfixe -type (du grec ancien τυπός, tupos, empreinte, marque). Celui qui écrit n’a plus à former les caractères. Au paradigme du mouvement se substitue celui de la marque instantanée, du clavier et de l’écran.
Ces définitions s’accordent en tout cas sur un point moins évident qu’il puisse paraître : un système d’écriture n’est pas une langue, et l’invention d’un nouveau système d’écriture n’implique pas forcément celle d’une langue ; elle est le système de règles régissant l’écriture. Ainsi, il peut exister plusieurs manières de transcrire une même langue. Par exemple, l’alphabet latin, accompagné de signes de ponctuation et de différents diacritiques, permet de transcrire le français par le biais de sa grammaire. De même, un système sténographique est généralement pensé pour transcrire une seule langue ; il existe ainsi différentes variantes de mêmes systèmes afin que ceux-ci puissent être utilisé pour d’autres langues.


1. Définitions

i. Art ou technique ?

À partir de ces quelques notions préliminaires, il nous est possible de réfléchir à la définition de la sténographie. La question de la différence entre art et technique, revenant plus globalement dans de nombreuses réflexions liées à l’écriture, se pose aussi avec notre tentative de compréhension de ce que représente notre objet d’étude.
Souvent suivie du sous-titre « l’art d’écrire à la vitesse de la parole », la sténographie souffre parfois d’être qualifiée d’« art ». Perçue à notre époque avec le sens artistique du terme, cette désignation renvoyait alors plutôt au pendant technique de la sténographie ; du latin ars, équivalent du grec ancien τέχνη, technè, qui donnera plus tard le mot technique. Dans cette étude, nous ferons référence à la sténographie comme étant l’ensemble des systèmes et des techniques permettant d’écrire en moins de temps qu’avec l’écriture usuelle. Le sténographe Jean-Baptiste Estoup (1868-1950) aborde cette question précise de la nuance lexicologique entre art et technique pour la sténographie, et arrive à la définition suivante :

« Sténographie : art d’écrire – à l’aide d’un système de signes scientifiquement combinés pour obtenir des tracés réduits – en moins de temps qu’au moyen de l’écriture usuelle. »

Estoup, comme Navarre, se positionne dans un héritage classique de la définition du mot art. En effet, jusqu’au xviie siècle, ce terme s’« appliquait à toutes les formes d’artisanat qualifié, aux œuvres, aux techniques spécialisées, aux technologies et aux métiers ». Plus récemment, Delphine Gardey (1967-) a proposé sa définition de la sténographie avec cette fois une approche contemporaine d’historienne des techniques :

« Les méthodes sténographiques développées en Angleterre du xvie au xviiie siècle puis en France à partir de la fin du xviiie siècle peuvent être définies comme des techniques de scripturalisation [ou de “mise en écriture”]. La sténographie permet l’inscription de l’oral dans l’écrit. […] Technologie de l’écrit, la sténographie est aussi une technologie du son, et, sans doute, la première technologie d’enregistrement de la parole. »

Gardey abonde dans la direction de la sténographie comme étant une technologie, à l’instar de l’écriture. Sa définition est en accord avec celle d’Estoup à condition que nous nous replacions dans sa terminologie. Moins concise, la proposition de Gardey est néanmoins plus explicite quant aux usages courants de la sténographie, mettant l’emphase sur son rapport au son – elle définit alors le terme sans fermer la porte à ses autres domaines d’application, comme a pu le faire Navarre dans sa proposition. Estoup comme Gardey laissent une certaine liberté à leur conception de la sténographie. La sténographie, bien qu’axée en priorité sur un archivage en temps réel de la parole, peut se décliner pour transcrire d’autres phénomènes : ceux du langage en général, ceux du son, du toucher, du visuel… Ainsi, tout système permettant d’écrire « en moins de temps qu’au moyen de l’écriture usuelle » relève de facto de la sténographie.

ii. Une hydre terminologique

Dans ce mémoire, nous utiliserons le terme sténographie de manière générique afin de faire référence à tous les systèmes abréviatifs répondant à la définition énoncée dans la section précédente. Nous avons aussi considéré terme tachygraphie (du grec ancien ταχύς, takhús, rapide), bien que moins courant, pour son importance relative avant que ne s’impose dans l’usage du français le radical sténo (du grec ancien στενός, stenós, étroit, resserré, court).
Afin d’aider le lecteur à réaliser la profusion de cette science qui représenta le gagne-pain de millions de personnes au fil des siècles, il est nécessaire de mentionner que des centaines (voire des milliers) de systèmes sténographiques se sont succédés pour constituer un véritable écosystème scriptural. Andrew Robinson (1957-) mentionne plus de quatre cents systèmes uniquement pour le monde anglo-saxon, et aucun inventaire se revendiquant exhaustif n’existe à notre connaissance concernant le monde francophone.
Cette diversité est la source d’une richesse langagière méritant à nos yeux de ménager un aparté pour aborder l’univers terminologique gravitant autour de notre définition. L’histoire de la sténographie, et en particulier celle de son siècle d’or, dont nous retracerons la chronologie plus loin dans cette étude, regorge d’inventeurs ayant cherché à marquer l’histoire, convaincus du génie de leurs idées. Albert Navarre eut la patience de compiler quelques noms aux étymologies foisonnantes en un lexique que nous avons pris le soin de reproduire ci-dessous. Celui-ci contient aussi bien des sténographies utilisées pour transcrire la parole que certaines pour les gestes, ou encore pour la musique. Quelques néologismes sont construits à partir du nom de l’inventeur en question ; les auteurs éponymes sont nombreux, même si la plupart se contentent de faire suivre le mot « sténographie » de leur nom de famille. Nous profitons de cette reproduction pour ajouter quelques termes glanés au fil de nos recherches, ceux-ci sont indiqués en italique.

Alphométrie (l’abbé Dehée, 1842)
Brachygraphie (p.r.e.l., 1825)
Callisténographie
Célégraphie
Chirologie (Petitpoisson, 1840)
Citolégie (Malatier, 1844)
Dassevillegraphie (Dasseville, 1843)
Dewikographie (de Wick-Potel, 1853)
Diagraphie (Marie, 1839)
Dromographie (Thierry Mieg, 1887)
Échographie (Main, 1812, Gontier, 1832)
Eugeniographie (Leroy, de son prénom Eugène, 1856)
Expédiographie (Barbier, 1808)
Express (Galmache, 1896)
Génigraphie (Matraya, 1832)
Graphodromie (Astier, 1816, Korff, 1820)
Hémipasigraphie (Jonain, 1858)
Homographie (Pompée ; Lady Scott, 1831)
Idéographie (Don S. de Mase, 1863)
Idéolographie (Dublar)
Ktypographie (Prongin)
Lacographie (Zalkind, 1811)
Logographie (Le Hodey, 1789 ; 1811)
Melotachygraphie (de Voldemar, 1797)
Mélographie (anonyme, 1860 ; Bertini, 1812)
Méloplaste (Galin, Paris, Chevé, 1817)
Métagraphie (Dr Thierry Mieg, 1885, Depoin)
Mimographie (Bebian, 1825)
Mnémotchenie (Vansynghel, 1840)
Monotypie (anonyme, an v)
Néographie (de néos, nouveau)
Néotypographie (Calmus, 1863)
Notographie (Vidal, 1819)
Okygraphie (Blanc, 1801 ; Godefroy, 1802)
Oxigraphia (écriture rapide)
Pansténographie
Pasigraphie (de Maimieux, 1799)
Pasisténotachygraphie (Pront, 1823)
Pédographie (Thierry Mieg, 1885)
Parlographie (Chappaz, 1889)
Phéographie (Contet, 1865)
Phonautographie
Phonégraphie (anonyme, 1826)
Phonographie (Thiburge, 1808 ; Pitmann, 1837 ;
Thierry Mieg, 1853)
Phononimie (Grosselin, 1864)
Phono-sténographie (Grosselin, 1854)
Photographie de la parole (Alex.)
Potélégraphie (de Wick-Potel)
Polysténographie
Psychographie
Rapidégraphie (Rocquemont, 1853)
Rhadiographie
Scotographie
Seiglographie
Séméigraphie
Sémiographie (Gourju, 1865)
Sénographie
Sialographie (Mick)
Sonographie (de Saint Denis)
Squiagraphie (Guilory, 1884)
Stemnéographie (Parruite, 1891)
Sténographie (Bertin, 1792)
Sténographie lambdoïde (J.P. Martin. 1887)
Sténochorégraphie (Saint-Léon)
Sténophonographie (Zimmermann, 1865)
Sténotachygraphie
Sténo-télégraphie (Cassagne)
Stétographie
Stigmatographie (Bertini, 1811)
Tachéographie (Ramsay, 1681 ; Patey, 1818)
Tacholographie (Boisduval, 1825)
Tachygraphie (Coulon de Thévenot)
Tonographie
Typophonie (Painparé, 1840)
Typosténographie (Patey, 1829)
Velographie
Vocographie (Richard, 1830)
Vocotypographie
Ypographia
Zigzagraphie (Dublar, 1833)
2. les différents paradigmes d’abréviation

La sténographie permet donc d’augmenter la vitesse de prise de note d’un scripteur. Cette section vise à décrire brièvement, mais de manière exhaustive, les mécanismes permettant de réduire le temps nécessaire à la scripturalisation. Dans cette partie, nous aborderons les trois paradigmes abréviatifs les plus couramment rencontrés que nous qualifions respectivement de phonémique, graphique et morphémique. Cette taxonomie nous servira lors de la suite du développement de notre argumentaire ; elle constituera une base grâce à laquelle nous illustrerons nos réflexions. Il est important de noter que ces paradigmes d’abréviation sont présents conjointement dans la plupart des systèmes sténographiques. Les systèmes permettant d’atteindre les vitesses de scripturalisation les plus importantes sont ceux faisant appel aux trois catégories de simplification. Par exemple, la sténographie Duployé intégrale, que nous décrirons en section i., utilise uniquement des mécanismes phonémiques et graphiques. La métagraphie d’Estoup (ou Duployé codifiée), elle-même basée sur la sténographie Duployé, ajoute une couche phonémique aux outils déjà élaborés au préalable par Duployé. Ainsi, ce second système permet d’atteindre des vitesses plus importantes que le premier, même s’il est en contrepartie plus difficile de se l’approprier.

i. Phonémiques

L’un des principaux mécanismes d’optimisation de la sténographie tient dans l’idée qu’il est plus rapide d’écrire un mot via ses phonèmes plutôt que de transcrire toutes les lettres qui le composent. Ainsi, de nombreux systèmes sténographiques associés à la langue française font abstraction des lettres muettes (comme les marques du pluriel, les h muets, les e muets). De même, les digrammes et trigrammes sont généralement rassemblés en un seul signe. Par exemple, le son [ʃ] du digramme ch a en général son signe propre, tout comme le phonème [ε] associé aux digrammes ai ou ei est rapporté à un seul et unique signe, commun à toutes les graphies du son [ε]. En d’autres termes, à chaque phonème est associé un unique graphème. En suivant cette logique, on comprend facilement que le nombre de caractères sténographiques d’un système est proportionnel à la richesse phonologique de la langue associée, c’est-à-dire le nombre de sons de la langue. Ainsi, des systèmes aux fonctionnements relativement proches, comme le Pitman pour l’anglais et le Duployé pour le français (figures 2 et 3), n’auront pas le même nombre de signes sténographiques, l’anglais étant plus étendu phonologiquement que le français.

ii. Graphiques

Un autre paradigme important concernant l’amélioration de la rapidité concerne la simplification du tracé. En calligraphie, l’ordonnancement des tracés formant un caractère est appelé le ductus ; c’est le terme que nous adopterons dans la suite de l’ouvrage. L’un des enjeux principaux de la sténographie est de réduire le nombre d’éléments composant un caractère afin de gagner en rapidité. Certaines lettres de l’alphabet latin nécessitent plus de mouvements que d’autres. Les caractères k ou w, par exemple, nécessitent trois tracés chacun. Un système sténographique bien construit comportera un ensemble de caractères facilitant le plus possible le ductus.
En addition à la réduction du nombre de tracés, la majorité des systèmes sténographiques les plus récents permirent d’enchaîner l’écriture des caractères de manière à combiner les formes. Ainsi, on nomme sténogramme un signe sténographique correspondant sémantiquement à un mot dans la langue associée. Un sténogramme peut être formé d’un seul caractère sténographique si le mot est monosyllabique, on parle alors d’inscription atomique. Avec un système rigoureusement phonétique, un mot polysyllabique est forcément représenté par une combinaison d’inscriptions atomiques et forme ainsi une inscription composée. La réalisation des formes composées nécessite l’apprentissage du système concerné : l’enchaînement des caractères sténographiques n’est généralement pas aussi trivial que l’enchaînement de l’écriture des lettres usuelles. Ces enchaînements sont codifiés, et les systèmes les plus développés les décrivent dans des tables combinatoires (figure 5) afin que chaque cas de figure soit anticipé et normalisé. Pour gagner en vitesse, les tracés sont simplifiés autant que possible ; l’enchaînement des caractères sténographiques est réalisé de telle sorte à ce que le ductus soit le plus simple et fluide possible. Dans cette idée, les angles ainsi que les levers de main sont évités au possible, comme illustré par la figure 4 ci-contre. Les sténogrammes pouvant être réalisés le plus rapidement sont ceux ne nécessitant aucun angle et pouvant être graphiés sans que l’outil utilisé n’ait à perdre contact avec le support.
Certains systèmes sténographiques reposent uniquement sur une simplification du tracé par l’omission des diacritiques d’un système usuel auxquels ils s’adaptent. On peut retrouver de nombreux exemples d’écritures répondant à ce critère mais n’étant pas revendiquées comme étant des systèmes sténographiques. Dans les langues sémitiques, nous pouvons citer à ce titre le rasm (francisation de l’arabe « رَسْم », trace) – l’écriture associée aux formes canoniques du Coran et faisant fi des diacritiques – ou encore l’hébreu et son système de simplifications permettant de ne pas écrire les voyelles, ces dernières pouvant pourtant être précisées par des diacritiques. Cette technique d’omission des diacritiques est très fréquente au sein des systèmes de sténographie. L’apprenant s’habitue d’abord au système en transcrivant les voyelles à l’aide de diacritiques, puis lorsqu’il est à l’aise et habitué au système, il peut simplifier le ductus et ne plus les différencier.

D’autres systèmes reposent sur un gain de temps plus organique de l’écriture, dans le sens où ces écritures tentent de forcer une évolution pseudo-naturelle du système d’écriture dominant associé à une langue. Concernant l’écriture du chinois, nous pensons notamment au genre calligraphique de la cursive permettant d’écrire les idéogrammes plus rapidement, principalement grâce à une diminution du nombre de tracés disjoints, et en omettant certains tracés, comme le montre les figures 6 et 35. Dans le monde anglo-saxon, un système sténographique obtint un relatif succès grâce à sa simplicité : l’orthic est un système consistant seulement en une redéfinition graphique des vingt-six lettres de l’alphabet latin dans l’objectif de diminuer la complexité du tracé de chaque lettre. Une fois que l’alphabet est connu, l’apprenant a fourni l’essentiel du travail nécessaire à une maîtrise du système.
En ayant uniquement recours aux abréviations phonémiques et graphiques, un sténographe peut espérer atteindre au maximum une vitesse de 80 mots par minute. À titre de comparaison, une conversation est tenue à environ 200 mots par minute. Pour espérer atteindre un rythme suffisant à la graphie en temps réel du discours, il faut ajouter les abréviations morphémiques aux deux premiers types d’abréviations.



iii. Morphémiques

La dernière principale mécanique mise en œuvre par les auteurs de systèmes sténographiques est aussi la plus complexe à apprendre. C’est souvent les points nécessitant le plus de temps d’apprentissage et d’adaptation au néophyte d’un système. Nous regrouperons cette catégorie de mécanismes abréviatifs sous le nom d’abréviations morphémiques. En linguistique, le morphème est l’unité linguistique minimale. Par exemple, le mot morphème est composé du radical morphé et du suffixe -ème, une marque signifiant élément de base. Le radical du mot et son suffixe sont chacun des morphèmes. Une analogie est possible avec par exemple la notion d’acronyme : un objet volant non identifié devient un ovni, le terme ovni devenant alors un morphème à part entière. En sténographie, les termes retrouvés de manière récurrente dans la langue peuvent être abrégés de sorte à ce qu’ils n’aient plus à être représentés sous leur forme phonétique mais avec un sténogramme distinctif. Par exemple, dans le cadre de la métagraphie de Pommier et Guaspare, on peut retrouver des abréviations courantes comme reproduit dans la figure 7. Les systèmes permettant réellement d’écrire aussi vite que la parole combinent généralement les trois paradigmes abréviatifs énoncés, et peuvent contenir plusieurs milliers d’abréviations morphémiques à connaître par cœur.


3. Un répertoire de formes commun

i. Étude formelle

Les systèmes sténographiques occidentaux récents se distinguent visuellement des autres systèmes de transcription du langage et sont facilement confondus entre eux du fait de leur proximité graphique. (figure 8) Leur ressemblance est parfois si importante que, dans certains cas, un sténogramme peut être lu dans plusieurs systèmes distincts et avoir un signifié totalement différent dans chacun d’entre eux. De nombreux systèmes dérivés du Duployé pourraient par exemple être lus comme un texte transcrit dans la version originale du Duployé, mais n’avoir aucun sens. Un équivalent serait de lire à voix haute un texte en anglais en étant uniquement francophone : le lecteur appliquerait la phonologie du français à la graphie de l’anglais. Rien ne l’interdit, ça peut même être utile, mais le résultat serait souvent difficile à comprendre pour quiconque n’ayant pas une bonne maîtrise du français et de l’anglais.
Cette proximité se manifeste visuellement par un vocabulaire graphique commun, un ensemble d’éléments de base tels que le point, le segment, la courbe, la boucle et le cercle. À partir de ces quelques formes élémentaires, des changements d’échelle, d’orientation et d’épaisseur de trait (en appuyant plus ou moins fort), il est possible de constituer l’extrême majorité des sténogrammes occidentaux. Pour illustrer cette évidente simplicité, l’Institut sténographique de France publia un kit d’accessoires appelé Le Petit Sténographe afin de permettre un apprentissage ludique de la sténographie aux plus jeunes. Celui-ci était constitué de treize formes canoniques (figure 9), en bois, à agencer ensemble à la manière d’un jeu pour enfant, avec lesquelles il était possible de constituer n’importe quel mot en sténographie Duployé.
C’est la contrainte de la vitesse qui dirigea la sténographie conventionnelle vers le répertoire formel quasi-normalisé que nous lui connaissons aujourd’hui. La qualité visuelle des sténogrammes en résultant est discutable ; la calligraphie était tout sauf une considération pour les sténographes. En étudiant la sténographie à travers le prisme de la calligraphie, il est difficile de retrouver une forme d’élégance aux sténogrammes cantonnés à une simple conjonction d’éléments dont la vocation était d’être simple et basique. Paul Claudel (1868-1955) notait « la lettre chinoise est vue de face, la lettre latine est vue de profil », nous ajouterons à cela que le sténogramme n’a pas de visage, si ce n’est celui de l’efficacité. La sténographie n’a rien de calligraphique, et bien que κάλλος (kállos, beauté) rime avec στενός (stenós, étroit), il serait hasardeux d’y trouver beaucoup d’autres rapprochements.
L’artiste Michel Danton (1952-) souligne que l’écosystème sténographique occidental a évolué sur un « mode darwinien [et] aurait retenu puis développé au fil des générations certains caractères morphologiques favorisant exclusivement [l’objectif de la vitesse]. ». C’est une hypothèse dont on peut constater la légitimité en retraçant l’arborescence chronologique des différents systèmes d’Europe occidentale. En effet, il n’était pas rare pour les auteurs de systèmes sténographiques de revendiquer l’héritage d’un autre système, prônant des améliorations à ce dernier. Ainsi, des liens de parentés, de véritables généalogies, peuvent être reconstitués sans mal. Au fur de nos recherches, nous avons d’ailleurs pu élaborer un arbre phylogénétique partiel des principaux systèmes en usage du xviie au xixe siècle (figure 10). La plupart des systèmes nommés dans la figure située sur la page suivante, de même que les détails historiques quand à leurs parentés, seront abordés dans la section I.b.1.iii. Renaissance sténographique, Révolution française et rationalisation de la démocratie.

ii. La question de la lisibilité

À ce stade de notre description, la question de la lisibilité de la sténographie se pose. Les simplifications graphiques importantes, l’abandon de l’orthographe au profit de la phonétique, le répertoire de formes restreint sont tous de bons arguments en la défaveur d’une lecture agréable de la sténographie. Certains auteurs solutionnent cette question en ne l’abordant pas, ou en avançant que les différents contextes linguistiques suffisent à comprendre une phrase. Dans les systèmes purement phonétiques, comme la Duployé intégrale, tous les homophones disposent de la même graphie. Il n’existe ainsi aucun moyen autre que le contexte pour différencier les mots prononcés [so] ; sot, seau, sceau et saut (sans compter leurs formes au pluriel). Pour certains, il s’agit seulement d’une habitude à prendre. Bien qu’Estoup défende l’idée qu’il soit possible de lire la sténographie aussi facilement que l’écriture usuelle, il admet :

« Mais, qu’il n’y ait pas d’illusions à cet égard. L’exercice de la lecture est, pour le débutant, plus difficile que l’exercice d’écriture. […] Afin de réaliser la rapidité nécessaire, il a fallu économiser le tracé au maximum. Pour un grand nombre de mots les signes ne représentent pas la totalité des éléments phoniques. Puis il y a les amphibologies : un assez grand nombre de signes donnent lieu à plusieurs significations. Aussi l’opération de la lecture constitue un travail assez complexe : il faut sans cesse choisir, deviner, en déterminant d’après le contexte et le sens général. »

Dans cette idée, qui de mieux placé que Blaise de Vigenère (1523-1596), l’auteur de la somme encyclopédique sur la cryptographie Traité des chiffres et secrètes manières d’écrire pour décider de la lisibilité d’un système d’écriture ? Vigenère a étudié les notes tironiennes, système que nous aborderons en détail dans la section suivante, et émit la conclusion suivante :

« C’est une profonde mer de confusion et une vraie géhenne de la mémoire, comme chose laborieuse infiniment, et avec tout cela inutile, parce que chacun peut se dresser à part soit des abréviations à lui propres et particulières. »


Ici, Vigenère met l’accent sur le fait que les scribes du Moyen Âge se servaient des notes tironiennes en tant que notes personnelles, ces écritures devenaient alors des systèmes non conventionnels, et impliquaient d’avoir recours à des méthodes de déchiffrement, l’une des spécialités de Vigenère. Ce constat quant à la difficulté inhérente aux notes tironiennes, tant sur un aspect de lecture que d’écriture, est partagé aujourd’hui par le paléographe Denis Muzerelle, qui émet de sérieux doutes sur leur lisibilité même. 
Le problème des systèmes de l’époque moderne ne se niche pas dans leur ésotérisme, mais bien dans la multitude d’homoglyphes et du nombre réduit de phonèmes représentables. En étudiant la sténographie à travers le prisme de la cryptographie, on arrive rapidement au constat que, dans nombre de cas, le contexte devient la clé de chiffrement permettant d’extraire le sens d’un message. Sans ce contexte, il est souvent impossible de parvenir à une transcription sûre en écriture usuelle. Nous reviendrons sur ces considérations plus en profondeur dans la section I.b.2.ii. Usage et travaux au xxie siècle.


b. Écrire aussi vite que la parole

L’histoire de la sténographie, bien que peu étudiée et presque entièrement absente du paysage académique contemporain, constitue une brique passionnante de l’histoire de l’écriture. La sténographie permit d’abord de nous faire parvenir des exemples fidèles de la rhétorique des antiques, mais occupa aussi une place indispensable de la machine démocratique française (et plus largement occidentale) jusqu’au début du xixe siècle. Dans cette partie, nous effectuerons un survol concis et partiel de l’histoire de la sténographie, principalement avec une approche technicienne. Il n’est pas question ici de s’atteler à la tâche immense que constituerait la rédaction d’une histoire de la sténographie, tâche qui a d’ailleurs déjà été en grande partie remplie par Navarre, Louis-Prosper Guénin (1843-1908) et son fils Eugène Guénin (1865-1931) en ce qui concerne l’histoire de la sténographie en France jusqu’au début du xixe siècle. Nous recommandons au lecteur intéressé par un panorama historique approfondi de se référer à leurs ouvrages sur l’écosystème français. Joseph Depoin (1855-1924), auteur de la préface de l’ouvrage de près d’un millier de page de Navarre, mentionnait aux lecteurs intéressés par l’histoire de la sténographie dans le reste du monde occidental les travaux suivants : « de Westby-Gibson, en Angleterre, de Krieg, de Zeibig, de Faulmann, en Allemagne ; de Rockwell, aux États-Unis ».
La fin du xviiie siècle et le début du xixe marquèrent très nettement une volonté de dresser une rétrospective de cette technologie. Le seul ouvrage publié en français au xxie siècle pouvant se placer dans cette continuité est celui de Gardey, qui constitua pour nous une porte d’entrée précieuse dans cet univers à travers son travail sur l’histoire de l’administration et des technologies de la démocratie. Le travail de Gardey nous permit aussi de mieux comprendre l’arbitrage technologique qui dût s’effectuer au cours du xxe siècle pour déterminer quelles technologies de communication allaient occuper la place que la sténographie détenait depuis la Révolution française.
Ainsi, nous verrons dans cette étude comment, où, et quand, a émergé la sténographie ; dans quelles conditions elle a pu se propager à l’Antiquité puis au Moyen Âge ; par qui et avec quoi elle était écrite. Nous nous attarderons plus longuement sur l’époque contemporaine, avec en particulier le xviiie siècle, véritable siècle d’or de la sténographie occidentale, où elle était aussi bien considérée comme une puissante technologie que comme un vecteur d’idéologies. Ensuite, nous verrons pourquoi la sténographie a périclité à partir de la fin du xixe siècle, pour finir sur un état de l’art de l’usage de la sténographie à notre époque. Notre approche sera centrée majoritairement sur l’écosystème français, bien que nous n’hésiterons pas à réaliser des apartés incluant d’autres zones du globe quand l’utilité s’en fera sentir.


1. Jusqu’à l’époque moderne

i. Antiquité

Les origines du premier système sténographique ne sont pas tout à fait certaines. Comme nous l’avons mentionné dans la section I.a.2.ii., certains systèmes graphiques issus des langues sémitiques possèdent des attributs propres à la sténographie. Des soupçons subsistent quant à l’existence d’un système d’écriture hébraïque, antérieur à tout autre, comme étant une première forme d’écriture sténographique. Il n’existait au temps de Navarre aucune preuve tangible capable de soutenir une telle hypothèse.
Le système sténographique reconnu comme étant le plus ancien est cependant bien issu d’une langue sémitique, ou plus précisément d’une langue chamito-sémitique : l’égyptien ancien. Au viie av. j.‑c., à l’époque saïte en Égypte, est constitué un système basé sur une simplification des hiéroglyphes : le démotique. C’est l’une des trois écritures gravées sur la pierre de Rosette avec l’alphabet grec et les hiéroglyphes. C’est en partie grâce au fait que le démotique soit une translittération des hiéroglyphes que ces derniers purent être déchiffrés. Dans leur ouvrage Histoire de la sténographie dans l’Antiquité et au Moyen Âge, le père et le fils Guénin reviennent sur le travail du bénédictin Dom Pierre Carpentier (1697-1767), un français qui fut le premier à s’intéresser aux notes tironiennes :

« 1o Les notes [tironiennes] sont une écriture composée d’un alphabet, de signes syllabiques en très grand nombre, et de signes arbitraires ou idéographiques.
2o Cette composition est exactement celle de l’écriture démotique, avec les caractères de laquelle […] les notes ont certains rapports, et permet de conclure à l’emprunt fait à l’Égypte, par l’intermédiaire des Grecs, pour la création de cette écriture abréviative. »

Dom Carpentier, en plus de confirmer le statut d’écriture sténographique du système démotique, propose l’hypothèse d’une continuité entre l’écriture démotique, les notes abréviatives grecques et les notes tironiennes. Les grecs, tout comme les scribes égyptiens avant eux, eurent aussi recours à des méthodes sténographiques. L’histoire retiendra en priorité Xénophon (vers 430 av. j.‑c.‑355 av. j.‑c.), philosophe, chef militaire mais aussi auditeur de Socrate, comme l’un des précurseurs de la sténographie antique. Il utilisa au ive siècle av. j.‑c. un système de sa conception pour transcrire les notes discursives de son aîné Socrate. Ce sont cependant les notes sténographiques dites « tironiennes » qui éprouvèrent la plus grande durée d’utilisation, dépassant de très loin la durée de vie de tout autre système. Bien qu’il y eût d’autres systèmes utilisés à l’Antiquité comme au Moyen Âge, aucun n’égala les notes tironiennes pour ce qui est du volume, mais surtout, et contrairement aux notes tironiennes, tout savoir leur étant associé est aujourd’hui disparu. Les premières utilisations de ces notes remontent au ier siècle av. j.‑c., et des traces de leur présence ont été attestée régulièrement jusqu’au xie siècle. C’est dans l’ouvrage de Plutarque, Vie de Caton d’Utique, qu’on retrouve la première mention des notes tironiennes. Il prêtait aux esclaves-scribes le poétique nom de séméiographes « parce qu’ils écrivaient par notes de lettres abrégées (σημεῖον, sêmeîon) ».
Marcus Tullius Tiron (vers 103 av. j.‑c.‑4 av. j.‑c.), esclave affranchi de Cicéron rapidement devenu son notarius (du latin secrétaire, sténographe, qui évoluera plus tard vers le français notaire) et l’un de ses amis les plus proches, est l’auteur éponyme des notes. Il les aurait inventées à la demande de son maître qui voulait adapter les notes grecques au latin afin de garder une trace physique de ses discours, ses paroles étant évanescentes par essence. L’œuvre constituée par Tiron formait un ensemble d’environ 1 100 notes. Ce répertoire ne cessa d’être enrichi, d’abord par Sénèque qui monta à 5 000 signes, puis s’étoffa tout au long du Moyen Âge. Le paléographe allemand Ulrich Friedrich Kopp (1762-1834) en recensa finalement 13 000. Ces notes, comme le souligne Dom Carpentier, mettent en œuvre différents dispositifs abréviatifs qui pourraient rentrer dans chacune des catégories de la taxonomie que nous avons établie. Elles ne constituaient pas un système complet : l’alphabet latin était toujours bien présent pour compléter les mots impossibles à transcrire avec les notes. Les notes de Tiron permettaient d’écrire le latin classique, ainsi que sûrement le grec ancien.
Dans un ouvrage récent, le paléographe et musicologue John Haines reprit le travail d’Isidore de Séville (vers 565-636) qui décrivit les notes tironiennes en latin. Haines prit le temps d’expliquer le fonctionnement d’une partie des notes en langue anglaise ; nous recommandons au lecteur de s’y référer pour en apprendre plus sur la logique sous-jacente des notes tironiennes ainsi que leurs difficultés. Dom Carpentier, quant à lui, dressa un début de dictionnaire biscriptural dans son Alphabetum tironianium, dont nous reproduisons ici une page (figure 11).

ii. Les notes tironiennes et le Moyen Âge

Comme mentionné dans la section précédente, les notes tironiennes gardèrent une place importante tout au long du millénaire qui suivit leur invention. Seulement, très peu de sources primaires existent encore aujourd’hui. L’une des raisons principales de cette absence est inhérente à la place qu’occupa la sténographie dans les processus d’archivage des savoirs ; la place d’un support intermédiaire. En effet, nonobstant un avantage indéniable de rapidité, la sténographie était l’outil d’une poignée de scripteurs experts et servait bien souvent comme un brouillon voué à être plus tard retranscrit puis disposé. En Europe occidentale, durant le premier millénaire ap. j.‑c., le papier était un luxe au même titre que l’était le parchemin. De ce fait purement économique résultait la conséquence que seul l’alphabet latin pouvait être inscrit sur des supports durables. Les discours, les notes, ou la tenue des comptes, étaient sténographiées sur un support moins onéreux et plus pérenne : les tablettes de cires. Ces supports fait à partir de cire d’abeille, utilisés dès la Rome antique et jusqu’au xviie siècle, ont vu leurs outils reproduits par Navarre (figure 12) et décrits par Guénin :

« Les tablettes de cire, désignées chez divers auteurs sous le nom de ceroe, tabuloe, codices, codicilli, pugillares, étaient faites de bois dur, débité en feuilles minces, de forme carrée oblongue. On les enduisait de cire, et on y écrivait avec un style ou poinçon. […] Les styles étaient conservés dans un étui. L’emploi des tablettes, on le comprend, était très fréquent. […] Ces tablettes étaient, en général, de simples carnets de notes, et, quand les mentions qu’elles avaient reçues étaient transcrites, on effaçait l’écriture en aplanissant la cire avec le manche du style. »

Les notes tironiennes n’avaient ainsi aucune vocation à être pérennisées. Les seules notes ayant obtenu un statut plus officiel furent utilisées en tant que sceaux, ou signatures. L’anthropologue de l’écriture Béatrice Fraenkel (1951-) a consacré un chapitre à cet épisode. Aujourd’hui, plus rien ne subsiste des notes dans nos vies quotidiennes si ce n’est un signe : l’esperluette. Ian Tschischold (1902-1974), dans son ouvrage dédié à l’étude de ce signe graphique à l’histoire si riche, a retracé les différentes formes par lesquelles est passé l’esperluette avant d’arriver à celles qu’on lui connaît maintenant. L’une des premières formes trouvées par Tschichold est celle d’une note dessinée par Tiron (figure 13), une sorte de lettre gamma capitale en miroir () est aussi présente dans l’alphabet de Dom Carpentier à l’entrée correspondant au mot latin et (figure 11), un mot qui a gardé la même signification jusqu’à notre français moderne.
Durant le Moyen Âge, les notes tironiennes étaient aussi amalgamées avec les sciences occultes. Alors que Trithème (1462-1516) étudiait lui aussi les notes dans son ouvrage Polygraphia, il fut accusé accusé de magie et couru le risque d’être mis au bûcher avec son livre. Ces savoirs n’étaient transmis que dans les monastères, et les quelques notarii formés ne s’associaient pas à n’importe qui : seuls les hauts dignitaires de la noblesse et du clergé pouvaient se permettre leurs services de manière ininterrompue à travers les siècles, et préserver ainsi ce savoir.
Le Moyen Âge et la difficulté de cette période finirent tout de même par avoir raison des notes tironiennes. Les multiples guerres et autres épreuves qui accompagnaient ces siècles compliquèrent évidemment le passage des connaissances à travers les générations, mais les notes tironiennes disparurent pour une autre raison : la perte du nombre de locuteurs du latin au profit des langues vernaculaires. Les notes tironiennes étaient pensées pour le latin, mais à la fin du Moyen Âge, celui-ci périclitait pour n’être finalement parlé que par une élite très restreinte. Ce changement fut progressif, si bien qu’il existe des textes en partie en langue romane et en partie en latin, qui permettaient encore l’usage des notes, comme on peut le voir dans le Manuscrit de Valenciennes, écrit vers l’an 1100 :

« Nous voyons se produire ce phénomène : les mots latins sont souvent écrits en notes, les mots romans sont transcrits en toutes lettres en écriture usuelle ; la note ou la syllabe manquait à l’écrivain pour les figurer sur le papier en sténographie. Par exemple, dans la phrase : “Faites vost almosnes ne si cum faire debetis, e faites vost elemosynas cert ço sapitis”, nous voyons écrits en notes dans le manuscrit les mots reproduits ici en italique, bien plus, la syllabe finale latine des mots romans faites et almosnes, dont le radical est écrit en caractères usuels, est transcrite en notes. »

Cette transition marquera la fin de l’usage des notes en France, si ce n’est pour quelques signes abréviatifs tels que l’esperluette et certains signes abréviatifs utilisés dans les minutes notariales et autres documents similaires. Ce ne fut néanmoins pas le cas partout, et l’enseignement des notes subsista dans certains pays d’Europe occidentale, comme l’Italie, où il ne cessa que bien plus tard.

iii. Renaissance sténographique, Révolution française et rationalisation de la démocratie

Le concept de sténographie fut très peu présent dans le paysage littéraire du au xviie siècle, les intellectuels y ayant accordé du temps étaient pour la plupart des cryptographes, comme ceux que nous avons cités dans les sections précédentes, qui y trouvaient une dimension curieuse et ésotérique. Il faut donc attendre plusieurs siècle pour que la sténographie trouve un regain d’intérêt, et qu’on lui retrouve des usages pratiques. Cette renaissance sténographique eut pour lieu d’origine l’Angleterre du début du xviie siècle.
John Willis (1575-1625), un ecclésiastique anglais, est connu pour être le père de la sténographie moderne. Il se retrouve en haut de l’arborescence que nous avons constituée dans la section I.a.3. Un répertoire de formes commun (voir figure 10). Nous aurions pu faire figurer avant lui Timothie Bright (1551-1615), qui publia en 1588 l’ouvrage Characterie; An Arte of Shorte, Swifte and Secrete Writing by Character dont Willis s’inspira, mais c’est véritablement Willis qui donna un nouveau souffle à la sténographie en Angleterre cinq cents ans après le déclin des notes tironiennes. Dans son ouvrage Art of Stenographie publié en 1602, Willis reprend le système alphabétique développé par Bright (figure 14) et y ajoute des mécanismes de liaison des caractères ; cette modification induit un gain de temps considérable, et préfigura l’invention de nombreux systèmes en Angleterre par la suite. Au fil des itérations, les formes prirent en maturité ; la profusion d’auteurs de systèmes dans la première moitié du xviie siècle fut cruciale pour parvenir à des paradigmes utilisables en conditions réelles de scripturalisation de l’oral. Navarre décrit ce phénomène d’évolution graphique ainsi :

« Petit à petit, [les figures] présentant des formes composées disparurent pour faire place aux signes simples, isolés ou pourvus d’un crochet ou d’une boucle, se prêtant mieux aux liaisons, une exécution plus aisée et plus rapide. »

De la sténographie de Willis découla celle de Byrom, de celle de Byrom le système de Williamson, et à partir de ce dernier, Samuel Taylor (vers 1749-1811) proposa en 1786 un nouveau système qui fit date : le système de Taylor. Avec son apport, Taylor s’appropria l’approche de Williamson pour l’adapter aux besoin des « hommes de profession » en essayant de « la simplifier et de la rationaliser de façon à créer une méthode qui puisse servir de “standard” (selon son expression) ». Contrairement à la plupart de ses prédécesseurs, la sténographie de Taylor garda de nombreux adeptes durant le demi-siècle qui suivit sa publication. Elle était dite « complète », c’est-à-dire que tout mot était compatible avec cette écriture, et Taylor assurait même qu’elle était « universelle » : son système pouvait être adapté à moindre effort pour n’importe quelle langue. Gardey cite Guénin à ce sujet, qui résuma le système de Taylor ainsi :

« Son alphabet est finalement composé de “quinze signes empruntés à la ligne droite, à la courbe et au cercle ; on n’écrit que les consonnes ; les voyelles initiales sont représentées par un point et les terminaisons par des signes spéciaux”. »
Treize des quatorze formes de base du système de Taylor sont les formes décrites dans la section I.a.3.i. Étude formelle. Seul le point est de trop ; mais il serait cependant malhonnête d’omettre la mention du fait que le Duployé – système dont il est question ici – gagne très nettement en lisibilité avec l’utilisation du point, dont l’usage est par ailleurs prévu dans la version dite « intégrale » du système. À l’instar de celle de Willis, la sténographie de Taylor influença de nombreux auteurs dont une figure de la sténographie française : Théodore Pierre Bertin (1751-1819). Après des études à Londres et son retour à Paris en 1791, Bertin constata l’« insuffisance des moyens disponibles pour noter le discours » et c’est ce qui le conduit naturellement à traduire en français la sténographie de Taylor qu’il avait apprise durant son séjour outre-Manche. Il publia sa traduction en 1792 sous le nom de Système universel et complet de sténographie, ou Manière abrégée d’écrire applicable à tous les idiomes, et réintroduit ainsi la sténographie en France.
À cette époque, la sténographie était un outil méconnu en France, et Bertin trouva le contexte politique parfaitement ajusté à l’usage d’une technologie de la notation rapide et fidèle. Gardey dresse une liste des arguments de Bertin, dont en voici un extrait :

« L’utilisation d’une prise de note permet, en recueillant les arguments adversaires, de déployer les siens. Bertin ne limite cependant pas la sténographie à la seule “capture des sons”, une utilité qui va prendre une signification toute particulière dans le contexte révolutionnaire français. La sténographie est une branche intéressante pour tous ceux qui “embrassent l’étude des lois et des sciences abstraites” […] L’écriture abrégée, qui doit être considérée, selon lui, comme l’“algèbre de l’écriture” , est définie comme “la faculté de retenir d’une manière exacte et correcte les arguments de leur adversaire”, comme le moyen de “suivre la plume les leçons des meilleurs professeurs”. »
La sténographie de Bertin n’était pas le seul système existant à cette époque, même si c’est lui qui la démocratisa et eut la plus grande importance dans la formation des sténographes à sa suite. Nous mentionnerons volontiers l’œuvre de Jean Coulon de Thévenot (1754-1813), qui occupa une place importante dans l’écosystème de l’époque, et qui développa son système tout au long de sa vie. Bertin et Coulon de Thévenot formèrent une part très importante de la génération de sténographes suivante, et furent parmi les sténographes les plus importants de la Révolution puis de la Première République. À la fin du xviiie siècle, la publicisation des débats était d’une importance cruciale dans le procédé démocratique : les régimes en place devaient prouver de leur sérieux. Par la suite, la sténographie développa aussi sa place dans le monde judiciaire, ainsi que dans le monde académique. La sténographie, en tant technologie de scripturalisation de l’oral, trouvait sa place ; et son moteur était toujours ce même soucis de transparence, d’archivage et de publicisation. Dans cette même réflexion, le xixe siècle était aussi témoin de la naissance et du développement de la statistique (de l’italien statista, homme ou femme d’État), qui avait alors pour but de fournir aux gouvernants des résumés de données quantitatives permettant d’éclairer leurs décisions. Ces données quantitatives se devaient d’être recueillies ; et ce, avec la même rigueur que les cessions parlementaires. La volonté de bien faire dirigeait les prises de décisions quant aux modes d’archivage. Gardey note à ce sujet que « le goût pour la lenteur et le travail bien fait sont des vertus professionnelles qui donnent de la valeur au produit réalisé. » Il ne faut pas cependant faire l’erreur de confondre sténographie et travail bien fait – la sténographie n’est qu’un intermédiaire vers le résultat final, une étape. Le texte sténographié est toujours présenté sous une forme calligraphiée et en écriture usuelle ; la sténographie, comme c’est le cas depuis la Rome antique, n’est que de l’ordre du brouillon et n’était pas conservée une fois retranscrite.
Toutes les étapes du processus juridique étaient ainsi relevées à l’écrit dans un soucis de justice et d’équité. Les cours des écoles normales et bientôt de toutes les facultés parisiennes furent sténographiés puis transcrits en écriture usuelle à des fins d’archivage. Ce processus de transcription est une constante à travers les époques : les textes transcrits avec des méthodes sténographes modernes ne sont que très rarement conservés en tant que tel ; au point où les documents dont le nom démarre par « Sténographie de […] » sont écrits en écriture usuelle, et ne portent ce nom seulement pour signifier qu’il s’agissait d’une transcription fidèle d’un texte qui, lorsqu’il fut prononcé à l’oral, n’était pas pensé en premier lieu pour figurer sur un support écrit.


2. Époque contemporaine

i. Âge d’or, révolution industrielle, déclin puis disparition

Après s’être rendus indispensables à la fabrique du savoir dans les hautes sphères de la société telles que la justice, la presse, l’enseignement supérieur, le législatif et l’Église, une nouvelle génération de sténographes entreprit de populariser la sténographie et de la rendre accessible au plus grand nombre. Nous noterons en priorité les travaux d’Isaac Pitman (1813-1887) en Angleterre et ceux de l’abbé Émile Duployé (1833-1912) en France. Les deux hommes ne révolutionnèrent pas la sténographie en proposant des systèmes plus rapides, mais ils le firent avec la manière dont ils partagèrent leurs travaux. Leur objectif n’était non pas de servir en particulier les intellectuels et les plus privilégiés de leur époque mais d’aller travailler de l’autre côté du spectre ; avec ceux pour qui l’écriture ne fait pas partie des habitudes.
La vie de Pitman était imprégnée de religion. Scribe infatigable, fervent croyant et prosélyte de la New Church, il fut d’abord enseignant dans une école baptiste, mais un différend d’ordre religieux le mena à clore sa carrière précipitamment. À la suite de cet épisode, Pitman entreprend la simplification de la sténographie de Taylor en réformant son approche de la phonétique. La phonography de Pitman sort en 1837. Gardey résume ainsi les intérêts de cet homme de religion :

« S’il rappelle les utilités éprouvées de la sténographie dans le domaine de la prise de note des sermons, conférences et procès, Pitman insiste sur le fait que la maîtrise d’une écriture abrégée permet d’écrire rapidement et exactement les idées qui viennent à l’esprit, procure un moyen commode de tenir un registre des copies de ses correspondances et permet, plus que toute autre technique, de gagner du temps. Ce gain de temps, précise-t-il, est particulièrement précieux pour ceux qui sont obligés d’occuper leurs journées à gagner leur vie et qui, comme lui, ne peuvent consacrer que quelques heures aux “activités de l’esprit” que sont la lecture et l’écriture. »

Contrairement à Taylor avant lui, Pitman ne met pas au cœur de ses priorités le rapport au travail, au commerce ou à la politique. Son projet est centré sur l’individu au travers de son rapport à la religion. En effet, par de-là son argumentaire sur une pratique personnelle de la sténographie, Pitman cherche à enseigner et à propager l’écriture de la Bible chez les plus jeunes. Dans cette idée, il oriente ses travaux vers une réforme de la langue anglaise afin d’en simplifier la graphie grâce à une écriture phonétique de cette dernière. Pour ce faire, Pitman dut innover quant aux méthodes de diffusion classiques des savoirs sténographiques. La plus judicieuse de ses trouvailles et la plus connue était la penny plate (figure 3), une planche permettant d’apprendre entièrement les bases de son système pour le prix d’un penny et qui figurait dans les salles de classe de l’époque. Pitman se retrouvait continuellement en déplacement pour enseigner son système aux quatre coins du pays. La conjonction de ces deux modes de diffusion, à savoir la publication et l’enseignement, permirent son succès entrepreneurial : il éradiqua bientôt toute autre concurrence en Angleterre. Encore aujourd’hui, le système sténographique le plus couramment rencontré dans l’univers anglo-saxon est le Pitman.
L’abbé ecclésiastique Duployé fut l’homologue français de Pitman. La vision utopique de Duployé comprenait de combattre l’illettrisme, de populariser l’écriture en l’apprenant aux enfants via la phonétique et en abolissant ainsi l’orthographe. C’est avec cette volonté qu’il commença la diffusion de sa méthode à la fin des années 1860. Pour arriver à ses fins, Duployé mit en place le même type de propagande que Pitman : des centaines de milliers de cartes postales, de fascicules en tout genre, de manuels furent édités et distribués gratuitement ou à des prix balayant toute concurrence. Dans la continuité de la penny plate, Duployé développa la clé de la sténographie Duployé (figure 2), qui fut reproduite dans de nombreux ouvrages duployens en plus d’être distribuée aux quatre coins de la France. Les deux hommes avaient pour objectif de faire adopter l’apprentissage de leurs systèmes en lieu et place de l’orthographe, à savoir dans les écoles primaires. Ces mentalités, comme les méthodes qui sont mises en place par Duployé et Pitman, ne sont pas des cas à part : la pensée qui anime les deux inventeurs se retrouva plus tard dans le projet espérantiste, né une vingtaine d’années seulement après le début de l’entreprise de Duployé, et par conséquent contemporains dans le développement. Les manuels d’apprentissage de l’espéranto figurait dans les mêmes collections que ceux consacrés à l’apprentissage de la sténographie. À cet égard, le xviiie et le xixe siècle furent très riche vis-à-vis des langues construites.
Ce succès n’était cependant pas sans critique, et les sténographes des prestigieuses institutions n’appréciaient guère la vulgarisation de leur art. Les Guénin faisaient partie de ces détracteurs ; malgré leurs capacités d’historiens, la lecture du présent de leur époque se révéla souvent conservatrice et anti-progrès, comme nombre des sténographes institutionnalisés de cette période. Une autre opposition à Duployé était concentrée en la figure d’Albert Delaunay (1828-1892), auteur du système Prévost-Delaunay, une adaptation de la sténographie d’Hippolyte Prévost (1808-1873). Cette opposition, au-delà de leurs différences techniques, aient surtout politiques : Delaunay fit connaître son système parmi les intellectuels et les sténographes d’état officiels. Le Prévost-Delaunay était présent à Paris, dans les écoles normales et autres hauts-lieux de la capitale. Le système Duployé était quant à lui surtout présent en provinces, mais gagnait des partisans à Paris. Les différentes itérations de la sténographie Duployé (intégrale, fondamentale, codifiée) permirent d’atteindre différentes vitesses, et ainsi différentes cibles, jusqu’à intéresser les sténographes professionnels. Le Prévost-Delaunay et le Duployé cohabitèrent très longtemps au sein même du corps des sténographes de l’Assemblée nationale, et alors que le rythme de l’innovation en sténographie déclinait, une nouvelle technologie commençait à émerger.
L’âge d’or de la sténographie s’étendit ainsi de la Révolution française à la fin du xixe siècle, et la raison à cela fut tout d’abord l’« inflation des écritures publiques » décrite par Gardey. Dans une certaine mesure, cette augmentation marqua aussi la perte de la sténographie : l’influence commerciale et industrielle des États-Unis, matérialisées par le taylorisme, encouragea la recherche du toujours plus, toujours plus vite et la prise de note fut réformée technologiquement au même titre que les autres domaines du commerce et de l’administration. Les premières machines à écrire inventées remontent au xviiie siècle. Leurs balbutiements aboutirent seulement un siècle plus tard à des machines assez performantes pour rivaliser avec la sténographie en matière de vitesse et de praticité, et c’est à la fin du xixe qu’on voit émerger une cohabitation équilibrée entre les sténographes et les dactylographes (du grec ancien δάκτυλος, daktulos, doigt). C’est à partir de cette période que le métier de sténodactylographe commença à émerger, au même moment où Remington, la marque américaine du typewriter par excellence, commençait à se faire un nom en France et à se démocratiser. La fin du xixe et le début du xxe marquèrent aussi un glissement social important, encore une fois conséquence de l’inflation des écritures ; un apport en main-d’œuvre se faisait sentir, et les femmes accédèrent progressivement à ces métiers de la prise de note, jusqu’alors toujours réservés aux hommes. Ces nouveaux postes de bureau, accessibles après une formation relativement courte, permettaient alors aux femmes une alternative au champ et au travail à l’usine. La transition est particulièrement flagrante aux États-Unis, où elles représentaient 4,5 % des sténodactylographes en 1870 pour 95,6 % en 1930. Cette mécanisation de l’administration ne se limite pas à la simple prise de note, mais est à tous les étages de cette dernière, et s’inscrit dans une série de mesures à visée purement productiviste : la rationalisation de l’environnement de travail, la question du rendement, des bâtons et des carottes, est tout aussi présente à l’usine qu’elle l’est au bureau. Ce changement de paradigme, caractéristique du management à l’américaine, est qualifié par Gardey aussi de changement « moral » :

« Du côté des valeurs, des normes, des modalités de définition du bon geste ou des critères de jugement relatifs au travail réalisé et à ses produits, une nouvelle “économie morale” se met en place : la vitesse succède à la sincérité, la malléabilité et la mobilité de l’écrit se substituent à la seule obsession de la sécurité et de la conservation. La confiance généralement déléguée aux humains et, en particulier, aux travailleurs qualifiés, est de plus en plus déposée dans les artefacts et les dispositifs et rendue “mécanique”. »

La confiance originellement accordée à la sténographie s’étiola avec les années, et les vitesses des meilleurs sténographes furent égalées par des dactylographes : l’usage des dix doigts, et le passage du tracé à l’instantané – du graphein au tupos – ont considérablement augmenté les vitesses de transcription. De plus, la production des machines à consistait en un document directement transcrit en écriture usuelle, donc final, et plus facile à lire (voir la section I.a.3.ii. La question de la lisibilité). Le temps long de l’administration et l’expertise des membres du corps des sténographes de l’Assemblée nationale leur permit de rester en fonction jusqu’en 2004. Aujourd’hui, rouleurs, releveurs et autres réviseurs qui travaillaient au perchoir de l’Assemblée ont été remplacés par des technologies automatisées ; des logiciels de reconnaissance vocale et de la captation vidéo, un parti pris totalement en accord avec la ligne suivie tout au long du xxe siècle.

ii. Usage et travaux au xxie siècle

De nos jours, en France et dans le monde occidental plus généralement, la sténographie est en voie de disparition. Elle n’est plus enseignée et presque aucun ouvrage n’est édité à son sujet. Sa pratique subsiste en tant qu’activité privée, personnelle, souvent exercée par d’anciennes professionnelles du secrétariat. Les personnes nées depuis les années 1990 n’ont en général pas connaissance de ces écritures abréviatives si elles n’ont pas dans leurs proches d’anciennes sténodactylographes. Même lorsqu’elles ont connaissance de la sténographie, les jeunes ne savent ni les lire, ni les écrire, et rien ne semble indiquer que la tendance puisse s’inverser.
Cet état de disparition avancée n’est pas aussi important partout. En Inde par exemple, bien qu’elle soit là aussi sur le déclin, la sténographie est encore très présente. L’état de la technologie concernant la reconnaissance vocale y est en retard, une conjoncture qui permet à la méthode de Pitman de toujours répondre à des besoins, et ce à tous les étages de l’administration indienne. Outre-Atlantique, la sténographie existe encore en tant qu’héritage d’une histoire particulière de la colonisation. Jean-Marie-Raphaël Le Jeune (1855-1930) était un prêtre canadien qui adapta le système Duployé au jargon chinook en 1890. La plupart des textes du jargon chinook étaient publiés en sténographie, et cette pratique persiste jusqu’à aujourd’hui dans l’intention de faire vivre ce pidgin.
Des communautés en ligne dédiées à la sténographie subsistent et sont encore actives. La plupart des sujets publiés concernent des demandes de transcription de notes personnelles trouvées dans des carnets ou des marges de livres. L’autre pan de l’activité en ligne émane de passionnés de la sténographie et de culture écrite, qui animent les communautés en proposant des activités régulières de transcription, ou qui développent un travail de recherche amateur sur l’histoire de la sténographie.
Dans le monde de la recherche scientifique, les différents systèmes abréviatifs sont l’objet d’étude de quelques articles en vision par ordinateur, en particulier dans le domaine de la reconnaissance de caractères. La sténographie, comme évoqué dans la section I.a.3.ii., pose des questions de lisibilité pour des raisons inhérentes aux paradigme  de combinaisons des syllabe et d’écriture phonétique de la langue. Ces propriétés propres à la sténographie en font un système quasi-cryptographique, et elles nous ont longuement questionné sur les rapports que pouvaient entretenir la sténographie aux machines : bien que la mécanisation – et à sa suite l’ordinateur – ait mené la sténographie à sa perte, que penser du fait que celle-ci soit robuste aux technologies de reconnaissance de caractères ? La recherche en reconnaissance de caractère est considérée par beaucoup comme une science « résolue », à savoir un domaine dont on a cartographié tous les recoins, mais ces savoirs s’appliquent en grande partie à des systèmes purement alphabétiques. Une approche informatique de la lecture de la sténographie met en exergue plusieurs strates de difficultés ; cette tâche est loin d’être triviale, et représenterait un objet d’étude intéressant pour le domaine de la reconnaissance de l’écriture manuscrite.
Une autre approche de la sténographie est aussi présente dans le domaine de l’informatique : celle de la production de signes typographiques. Il existe à ce jour quelques logiciels permettant de représenter algorithmiquement les sténogrammes. Au cours de nos recherches, nous avons pu repérer deux projets dignes d’intérêt : le premier consiste en une adaptation sous licence libre du système Duployé et de ses variantes en un fichier otf, un format de fonte numérique standard permettant d’utiliser une police typographique sur un ordinateur. À terme, l’objectif de ce projet est de permettre à chacun de taper sur son clavier la transcription phonétique d’un mot puis de le voir matérialisé à l’écran dans sa version sténographique. Le second projet date de 2008, et utilise une technologie aujourd’hui presque totalement inusitée (metafont) afin de permettre dans un premier temps une transcription phonétique, puis une transcription sténographique ; ici, différents systèmes ont été implémentés. Le logiciel fourni émanant d’un chercheur, Stanislas Jan Šarman, celui-ci a le mérite d’être rigoureusement documenté, et ainsi de rendre compte précisément de la méthode élaborée afin de modéliser mathématiquement les différents signes sténographiques. À l’instar du travail de recherche effectué quant à la reconnaissance de caractères, les articles de Šarman nous permettent d’apprécier la complexité que représente la manipulation informatique des graphies non alphabétiques. Encore une fois, il nous semble important de souligner l’ironie de cette démarche : la sténographie est une technologie éminemment manuscrite, et l’adaptation des paradigmes graphiques très simples qui servent de base à la sténographie sont un problème tout sauf trivial pour nos programmes contemporains, qui n’ont pas été pensés pour gérer cette catégorie de systèmes d’écriture.


c. Sténographie musicale : écrire aussi vite que la musique

l’histoire, dans son sens académique d’étude du passé, a retenu jusqu’à présent la sténographie exclusivement comme une transcription de la parole. En effet, même si des auteurs comme Gardey, Navarre et Guénin ont réussi à sauvegarder cette partie de l’histoire des techniques, il existe cependant toute une face de la sténographie que ses historiens majeurs ont éludé : celle de la sténographie musicale. Il n’existe à notre connaissance aucun ouvrage en langue française retraçant l’histoire de la sténographie musicale. Nonobstant une profusion moindre, ces méthodes de notation de la musique ont cependant fait l’objet d’un certain nombre de systèmes – avec des innovations graphiques plus ou moins intéressantes, mais l’intention première reste pertinente. Ainsi, nous proposons cette définition de la sténographie musicale en agrégeant celles proposées pour la sténographie en section I.a.1.i. : la sténographie musicale représente l’ensemble des techniques de scripturalisation de la musique qui permettent des tracés réduits, à l’aide de signes scientifiquement combinés, en moins de temps qu’au moyen de l’écriture usuelle.
Dans cette section, nous retracerons brièvement l’histoire de la notation musicale occidentale à partir de l’invention des neumes à l’Antiquité ; la première innovation graphique qui permit de dissocier les paroles de la prosodie. À compter de cette origine, nous retracerons le chemin que suivit le système de notation musicale dominant, qui intégra d’abord la portée, puis d’autres paradigmes graphiques avant d’aboutir sur un consensus relativement stable qui conduisit au système de notation que nous connaissons tous aujourd’hui. À cet égard, et à défaut de bénéficier d’un nom plus singulier, nous emprunterons à Jean‑Yves Bosseur (1947-) la terminologie « système solfégique » pour faire référence au système de notation musicale occidental usuel. Nous aborderons ensuite plus généralement la question de la partition et mettrons en exergue les principales problématiques qui en découlent. Une fois ce cadre établi, il nous sera ensuite possible de nous atteler à l’étude des systèmes de sténographie musicale existants et déterminer ainsi en quoi ces derniers peuvent remplir l’objectif qui leur incombe : écrire aussi vite que la musique.


1. Une brève histoire du système solfégique

Les premières notations musicales ont été inscrites à la même période que les premières écritures. Noter la musique a toujours été une question importante pour les civilisations maîtrisant l’écriture, et des traces de notations musicales vieilles de 3 800 ans ont été retrouvées, et comme le dit l’anthropologue Tim Ingold (1948-), « il ne peut pas y avoir d’histoire de l’écriture qui ne soit aussi une histoire de la notation musicale ». À cette époque, et ce fut valable aussi pour tout le reste l’Antiquité, la musique était notée textuellement : seules les paroles permettaient de transcrire les chants. Le texte prend donc une place centrale et suffisante. La musique instrumentale, quant à elle, n’était pas graphiée et la partition était là encore ce même texte.
C’est à l’Antiquité que paroles et prosodie commencent à se détacher pour la première fois. Ingold, dans son ouvrage Une brève histoire des lignes, qui sera l’une de nos références principales pour la présente section, résume bien leur première occurrence historique :

« Un système de notation pour les accents dans les textes grecs et romains fut introduit par Aristophane de Byzance, bibliothécaire d’Alexandrie autour de 200 av. j.‑c. Ceux-ci furent appelés neuma [νῆμα], mot grec signifiant “geste” ou “signe”. Il existait deux accents principaux, l’aigu et le grave, indiquant respectivement un accent vers le haut ou vers le bas. Ceux-ci pouvaient se combiner et former des accents en forme de v ou de n pour représenter les inflexions vocales les plus complexes. C’est donc sous cette forme que les “neumes” firent leur apparition, précurseurs dans l’histoire occidentale de l’écriture d’une notation spécifiquement musicale qui fut utilisée pour le chant grégorien. »

Avant que les neumes soient actualisés au Moyen Âge, aucun système de notation de la musique n’arrivait à s’imposer. À ce sujet, Isidore de Séville alla même jusqu’à déclarer au vie siècle qu’il était impossible d’écrire la musique. Il fut contredit au ixe siècle avec le développement des chants grégoriens (ou plain-chant) et leur transcription par des accents d’intensité, la notation neumatique. Ingold continue son exposé en décrivant graphiquement les origines du système utilisé au Moyen Âge avec les deux inscriptions atomiques le composant, à savoir la tige (virga) et le point (punctum). De ces deux formes simples étaient déclinés tous les neumes, qui pour la plupart étaient des inscriptions composées de ces deux éléments. Ce système détenait très clairement des caractéristiques sténographiques de par sa simplicité. Seulement, étant donné que les neumes ne pouvaient pas exister par eux-mêmes mais toujours en support d’un texte, il ne peut pas être qualifié de sténographie musicale. Il faudra ensuite attendre l’apport de Guido d’Arezzo (vers 992-1050), un moine bénédictin italien célèbre pour ses talents de pédagogue musical, pour qu’une avancée soit faite dans le domaine de la notation musicale. Au début du xie siècle, seuls les étaient connus pour permettre aux moines d’apprendre les chants. Cette méthode impliquait de nombreuses difficultés d’apprentissage, en particulier pour déterminer la hauteur des notes. D’Arezzo remarqua ce problème et essaya d’y répondre en inventant la portée à six notes et quatre lignes, qu’il enseigna et démocratisa grâce aux paroles d’un chant liturgique mnémotechnique. Ce nombre de lignes varia pour finalement se fixer à cinq à la Renaissance, et les six notes évoluèrent pour devenir la gamme que l’on connaît aujourd’hui : la gamme diatonique, do ré mi fa sol la si do. Cette échelle, ainsi que la portée à quatre lignes, constituèrent les prémisses de ce qui devint plus tard le système solfégique. De nombreux ajouts, comme entre autres les clés, les altérations, les figures de notes, les indications de tempo et de nuances, vinrent s’ajouter au fil des siècles pour compléter les besoins des musiciens et des compositeurs. Le système se stabilisa pour obtenir autour du début du xixe siècle le système solfégique que nous connaissons aujourd’hui. Comme le dit Bosseur, « [o]bserver la notation à travers les époques successives de l’écriture musicale aide à saisir les attributs du monde sonore que les musiciens se sont efforcés de privilégier compte tenu des mutations de leur langage. ». Le système solfégique d’aujourd’hui décrit la musique occidentale comme la musique le décrit en retour, les deux ayant coévolué jusqu’à aujourd’hui. Dans la suite de cette étude, nous verrons en quoi ce système est d’autant plus questionné depuis l’avènement de l’informatique musicale.

2. Histoire et place de la sténographie musicale du xviiie au xxe siècle

En préambule de cette partie, nous avons déclaré que l’histoire de la sténographie musicale n’avait pas encore été écrite. En effet, aucun synoptique ne permet de comprendre les tenants et aboutissants de l’histoire de ces systèmes notationnels d’une manière aussi extensive qu’avec la sténographique classique. Les quelques sources secondaires disponibles sur cette question figurent dans notre bibliographie et permettent d’aborder uniquement la sténographie musicale en survol. Malgré ce manque, il se trouve qu’une pléthore d’alternatives sténographiques au système solfégique se succédèrent au cours de la chronologie brièvement décrite en section I.c.1. Dans la présente section, nous consacrerons nos efforts à l’étude de la sténographie musicale du xixe siècle, siècle d’or sténographique et époque concordant avec le pic d’activité de la sténographie musicale. Ainsi, nous nommerons les principaux protagonistes de cet écosystème, rappellerons le contexte politique dans lequel ces innovations surgissent, et expliciterons les volontés des différents inventeurs. À ce stade, il nous semble important de rappeler au lecteur que, n’étant ni musicien ni musicologue, nous ne sommes pas qualifié pour pour porter un jugement sur la validité de ces systèmes ainsi que sur leur bien-fondé, et que personne ne nous le demande. Nous nous en tiendrons ici à une approche descriptive et historique condensée à partir des sources que nous avons pu consulter. Les hypothèses quant à la possible réhabilitation de la sténographie musicale, reprenant potentiellement certaines idées énoncées ici, viendront plus tard dans cette étude et devront inévitablement être confirmées empiriquement.
D’après Christian Goubault (1938-2009), bien que le système solfégique se soit imposé et stabilisé dès le début du xixe siècle, de nombreuses tentatives de simplification et d’amélioration graphiques voient le jour. Il note :

« Dans tous les domaines, le xixe siècle innove et spécule, parfois avec une ingéniosité qui méritait un meilleur sort que l’abandon et l’oubli. De multiples essais sont effectués pour modifier le graphisme et simplifier l’écriture musicale – en réduisant les lignes de la portée et les clés, en supprimant notamment les altérations – ou pour créer de toute pièce d’autres systèmes, qui eurent une durée de vie éphémère. »

La sténographie musicale, avec d’autres systèmes notationnels, coche toutes ces cases. Goubault constate la présence de cette effervescence créatrice dans toute l’Europe occidentale sans pour autant tenter de lui déterminer de cause autre que le contexte scientifique global. Nous pouvons sans difficulté rapprocher ces inventions aux autres innovations graphiques et linguistiques qui caractérisèrent le xviiie et xixe siècle, comme mentionné précédemment. La volonté humaniste d’inclure chacun dans la société se retrouve dans ces systèmes, avec par exemple le Klavarskribo (de l’espéranto écriture pour clavier) du néerlandais Cornelius Pot qui permet de facilité la lecture des notes du piano à la manière d’une tablature, ou encore la notation en relief pour les aveugles de Louis Braille. Ces questions étaient si prégnantes dans l’esprit politique de l’époque que même des personnages comme Charles Fourier inventèrent leurs systèmes de notation musicale simplifiée vers 1820. En plus des autodidactes, des compositeurs et des musiciens, les sténographes professionnels de l’époque s’approprièrent aussi ces questions, et des protagonistes de l’histoire de la sténographie s’essayèrent à la sténographie musicale. Dès 1787, Coulon de Thévenot proposa un système pour transcrire la musique au rythme qu’elle se joue. Les figures 16 et 17 proviennent d’une planche résumant sa proposition. En 1817, Aimé Paris, auteur éponyme de la méthode sténographique Aimé Paris (voir figure 10), s’allie avec deux musiciens et une musicologue – sa sœur, Nanine Paris-Chevé ; il s’agit d’une affaire de famille – afin de proposer une sténographie musicale basée sur un projet de notation musicale de Jean-Jacques Rousseau : la « Méthode Galin-Paris-Chevé », ou « méloplaste ». En 1833, Hippolyte Prévost adapte son système sténographique à la musique ; ainsi, un lien de parenté direct entre la sténographie de Willis et la sténographie musicale existe via des systèmes comme la sténographie musicale de Prévost.
Une première remarque peut-être faite de ces différentes tentatives : tous ou presque sont destinés à la transcription du solfège. Certains sont développés avec une visée de simplification du système solfégique, d’autres portés sur l’accélération de la scripturalisation de la musique, afin de développer une technologie de prise de note musicale efficace alternative au phonographe d’Edison. Tous se veulent critiques de l’écriture usuelle, mais l’utilisent comme référent quant à la qualité de leurs idées. Leurs motivations sont souvent très différentes ; par exemple, le compositeur Charles Grelinger (1873-1942) proposa un système de transcription de la musique basé sur une partie de l’alphabet latin à laquelle on aurait ajoutée une série de diacritiques, il déclare :

« Mon ouvrage se borne donc à proposer un système de notation rapide qui, dans diverses circonstances, peut présenter des avantages pratiques dont j’ai fait l’épreuve.
La sténographie ne saurait remplacer l’écriture : elle la supplée seulement dans des conditions de hâte, saisissant la parole au vol, et parvient à fixer la pensée dans le temps même qu’elle est exprimée. Les signes abréviatifs sont ensuite traduits et l’écriture reprend ses droits. »

À l’instar du journaliste qui se doit d’être réactif lorsqu’une phrase pouvant faire un article est prononcée, le compositeur n’a pas beaucoup de temps à sa disposition pour transcrire la mélodie qui lui vient le temps d’un instant. Cet argument sera partagé par d’autres, comme Jean Kutahialian, l’ultime et le plus fervent défenseur de la sténographie musicale au xxe siècle. Kutahialan est arrivé sur le tard. Il était alors docteur en sténographie et auteur d’une méthode de sténographie musicale. Il a notamment publié le dernier système de sténographie musicale connu, accompagné d’un manuel adaptant son système à l’espéranto. Il fait partie de ces quelques intellectuels ayant fondé leur carrière au moment où la sténographie périclitait, et fut ainsi l’avocat passionné d’une technologie sur le point de disparaître.
De nombreux autres systèmes de sténographie musicale existent, basés sur différents paradigmes et ne présentant pas forcément de liens entre eux. L’un des plus connus est celui de Léon Labatut, qui est aussi l’un des plus complexes à apprendre. Toute une liste pourrait être ainsi établie et étudiée, mais nous tenterons ici de garder une approche générale. Nous pouvons classer les systèmes de sténographie musicale en trois catégories. Premièrement, ceux basés sur la portée du système solfégique, comme avec la mélo-tachygraphie de Michel Woldemar (figure 18). Deuxièmement, les systèmes s’inspirant de la portée pour définir une base quant à la hauteur des notes, comme avec le système de Prévost (figure 19) et où chaque sténogramme illustre une mesure (un mot musical, en quelque sorte). Troisièmement, il existe aussi des systèmes complètement désolidarisés de la portée comme avec le système de Baumgartner (figure 20), inspiré du système sténographique Gabelsberger, très répandu dans le monde germanique. Ce dernier peut retranscrire la hauteur, le tempo, la mesure, etc., dans un système aussi beau que complexe et partageant de nombreuses qualités graphiques avec une écriture cursive de l’alphabet latin. Ce dernier système part du postulat que les motifs musicaux sont à la base de toute composition. De cette hypothèse, Baumgartner met en place toute une série de mécanismes abréviatifs permettant de compresser toutes les répétitions successives d’un même motif en très peu de tracés, à la manière d’un algorithme de compression sans perte. Chacun des systèmes susnommés comportent forces et faiblesses dont les auteurs étaient sûrement plus ou moins conscients. Nous n’entrerons pas dans les détails de ces qualités et défauts, mais le lecteur intéressé pourra trouver une étude des systèmes de Woldemar et Prévost dans l’ouvrage de Frédéric Hellouin (1864-1924), et J. Mackenzie Pierce prit le temps de décrire en largeur le système de Baumgartner. Il est indéniable cependant que tous ces systèmes remplissaient au moins partiellement la mission pour laquelle ils furent imaginer : écrire plus rapidement la musique.
Paradoxalement, l’abondance créatrice autour des sténographies musicales n’a pas résulté en une adoption, ni par les compositeurs, ni par qui que ce soit d’autre. Tous ces systèmes abréviatifs restèrent au stade expérimental, et il n’existe aucune évidence historique permettant d’affirmer que l’un de ces systèmes ait un jour permis la transcription d’une œuvre complète, ni même d’un mouvement. Certains compositeurs comme Hector Berlioz (1803-1869) l’ont très certainement utilisée pour rédiger des brouillons, prônant toujours cet argument de devoir écrire une idée aussi vite que possible avant qu’elle ne disparaisse. D’autres compositeurs, comme Gioachino Rossini (1792-1868), au contraire, ne voyaient en ces méthodes aucun intérêt, déclarant qu’une éducation musicale rigoureuse suffisait à développer la mémoire, au point où transcrire un opéra entier après une seule écoute devenait très accessible. En général, ce n’est pas à ce type d’audience au talent génial que s’adressaient les auteurs de systèmes de sténographie musicale ; ces essais de simplification étaient destinés le plus souvent au plus grand nombre, dans une volonté utopique de rendre la musique traditionnelle plus accessible, ou pour permettre aux compositeurs de faciliter leur travail. Seulement, très peu des auteurs de ces systèmes étaient aussi compositeurs. D’une part, ils ne connaissaient pas assez bien la musique pour permettre de proposer des systèmes permettant de prendre en compte toutes les potentialités qu’elle recèle, et d’autre part, le développement de l’oreille musicale n’était jamais une préoccupation présente dans les différents manuels. Quel que soit le niveau de connaissance de la musique, l’utilisateur du système n’y trouvait pas son compte. Dans le premier cas, il se retrouvait frustré avec un système inadapté à la composition, et dans le second il n’avait pas l’oreille assez développée. Il est aussi intéressant de noter qu’à partir d’un certain de niveau de maîtrise, les compositeurs ne se limitaient plus simplement au système solfégique mais inventaient aussi leurs propres paradigmes notationnels personnels pour combler les manquements de l’écriture usuelle. À cette époque, la connaissance de ce fait n’était pas aussi répandue. Grelinger, se questionnant précisément sur cette question, note finalement :

« Qui sait si ces grands maîtres auraient dédaigné la sténographie musicale ? Et qui sait s’ils n’avaient pas à eux une méthode ou un moyen de noter leurs impressions, et qu’ils ont négligé de nous transmettre ? »

Comment est-ce que tout un écosystème plus de soixante-dix systèmes référencés a pu autant se développer en restant intégralement en vase clos ? Nous avons déjà avancé plus haut quelques éléments de réponse, mais la principale raison à cela semble être que les espoirs placés en la sténographie musicale étaient fondés sur le succès de la sténographie de la parole. Comme nous l’avons montré en section I.b.2.i., la sténographie avait une place décisive dans la société du xixe siècle au début du xxe siècle. Elle était omniprésente, et était un instrument clé de la démocratie. Cet engouement fut transposé sans peine sur la sténographie musicale, qui agit comme un véritable carburant pour les sténographes intéressés par la musique. La sténographie de la parole, avec son statut de technologie de l’écriture, entretenait alors des liens étroits avec le monde de l’édition ; les partitions de musiques imprimées, avec leurs spacieuses portées toutes notes transcrites, étaient coûteuses. Certains voyaient en la sténographie musicale un intérêt économique grâce à ses propriétés de compression des tracés. L’histoire retiendra que cet argument ne suffit pas, et il est probable que celui-ci n’aurait pas été assez fort si en contrepartie son homologue de la parole n’avait pas rencontré de telles réussites. À ce sujet, Hellouin conclut :

« La sténographie musicale n’a plus aucune espèce de raison d’être. Pour recueillir la musique à l’audition, le phonographe l’emporte sur elle. Pour l’appréhension de l’idée fugitive du compositeur, la notation usuelle, habilement utilisée, suffit amplement.
Si donc, un beau jour quelqu’un affirme porter, suspendue à sa ceinture, la clef du problème, ce ne pourra être qu’un mystificateur pensant s’égayer à nos dépens, ou un exalté, dans l’esprit duquel fleurit la douce illusion. Dans le premier cas, tournons le talon. Dans le second, saluons et laissons-le passer. »

Une critique acerbe qui refroidirait plus d’un à s’atteler à l’étude de nouveaux paradigmes sténographiques. Certains flaireront cependant une pointe d’espoir dans le champ lexical quelque peu cynique qu’Hellouin emploie ; penser des systèmes notationnels alternatifs de la musique est une belle idée. Imaginer pouvoir graphier les sons dans la même temporalité qu’on les perçoit, et ce sans l’aide d’une médiation externe, reste un doux rêve qui mérite qu’on s’y attarde. Jusqu’à présent, aucune entreprise ne permit d’approcher une solution. Les sténographes cherchaient alors une écriture cratylique de la musique. En d’autres termes, ils voulaient découvrir une écriture permettant de « constituer [naturellement] une langue générale écrite de tous les sons » ou encore d’écrire la musique « sans penser à l’écriture en elle-même ». Sans succès pour le moment, donc. Mais en proposant leurs systèmes, ces sténographes et autres compositeurs ont révélé à nouveau le fort lien qui unie son et signe ; un lien fortement ancré en l’humain et qu’il est encore nécessaire, nous le croyons, de questionner.


Deuxième partie : Pour une réhabilitation de la sténographie : une approche technologique & musicale

a. Les technologies de notation musicale

Après avoir posé ce cadre historique et conceptuel, il conviendra d’explorer plus en détails les différentes pistes de solutions imaginées par les compositeurs pour déroger à l’utilisation des systèmes basés sur la portée. Ces différentes approches sont résumées et classées dans la typologie d’Erhard Karkoschka (1923-2009), que nous prendrons le temps de décrire.


1. Qu’est-ce qu’une partition ?

i. Différence entre un texte et une partition

Lorsque la question de la notation musicale est abordée, aucune réponse ne peut être argumentée correctement sans avoir défini au préalable la notion de la partition musicale. Dans la plupart des cas, une partition réfère à un document transcrivant dans le système solfégique une œuvre musicale – c’est de surcroît la définition en vigueur au cnrtl, qui précise que le mot partition nous provient du latin partitio (partage, division, répartition). Seulement, comme nous l’avons vu dans la section précédente, le système solfégique n’est adapté qu’à un type de musique bien précis : la musique occidentale savante, construite sur la gamme diatonique (ou chromatique). Cette musique n’englobe qu’une infime partie des possibilités du spectre musical. Les musiques populaire, microtonale et électroacoustique, les musiques orientales, ne peuvent être transcrites ni correctement ni efficacement en ayant recours uniquement au système solfégique.
Au-delà de ces problèmes de représentation graphique, une autre question émerge : quelle est la fonction d’une partition ? À défaut de proposer des réponses arrêtées à cette vaste interrogation, nous essaierons dans cette section de proposer au lecteur des pistes de réflexion et d’établir un cadre dans lequel nous pourrons développer les idées explicitées dans la suite de cette étude.
Un premier auteur nous aiguillera dans notre tâche : Nelson Goodman (1906-1998), philosophe américain et auteur des Langages de l’art. Dans cet ouvrage, Goodman donne une définition de la partition en creux d’une question orientée par ses questionnements sur les rapports entre art et linguistique : quelle est la différence entre un texte et une partition ? La citation de l’auteur résumant le mieux sa posture est la suivante :

« Une partition, qu’on l’utilise ou qu’on s’en passe pour conduire une exécution, a pour fonction primordiale d’être l’autorité qui identifie une œuvre, d’exécution à exécution. […] [T]oute partition, en tant que telle, a pour fonction logiquement antérieure d’identifier une œuvre. »

Grâce à cette approche, Goodman arrive à se sortir du paradigme solfégique en se recentrant sur l’utilité de la partition, qui selon lui serait d’identifier une œuvre indépendamment de la méthode de transcription. Avec cette définition, des partitions – documents ainsi revendiqués – de compositeurs contemporains comme John Cage (1912-1992) ou François Bayle (1932-) ne seraient pas considérés en tant que tel. En effet, lorsque ces partitions sont jouées, les degrés d’interprétation et d’improvisation sont trop important pour permettre à deux musiciens ne s’étant pas concertés préalablement de produire les mêmes sons. Cependant, il ne fait pas confondre pour autant la liberté d’interprétation laissée au musicien avec un manque de précision, Pierre Boulez (1925-2016) le précise de la sorte :

« La notation deviendra suffisamment – mais subtilement – imprécise pour laisser passer entre ses grilles – diagramme d’hypothèse – le choix instantané et changeant, moiré, de l’interprète. On pourra allonger ce silence, on pourra suspendre ce son, on pourra accélérer, on pourra à chaque instant… ; bref, on a choisi désormais d’être méticuleux dans l’imprécision. »

Malgré une certaine précision dans l’imprécision, Goodman qualifie ces partitions de « pseudo-partitions » et les systèmes utilisés de « pseudo-notationnels ». Cette approche de la question nous semble trop radicale, trop restrictive, mais se fond bien dans le reste de la pensée logicienne de Goodman. Dans la suite de son développement, il liste cinq réquisits permettant de différencier une partition d’une pseudo-partition, et qui qualifient ainsi ce qu’est une partition. Ces réquisits permettent principalement de différencier les intentions du compositeurs et ainsi de supprimer toute ambiguïté pouvant subsister lorsque le musicien joue la partition.
Une autre idée de Goodman nous aide à mieux circonscrire le terme partition : la différence entre le partition et ce qui caractérise un texte, qui se situe encore une fois dans la fonction de l’objet, mais aussi dans son statut :
« Nous avons vu qu’une partition musicale fonctionne dans une notation et définit une œuvre […] et qu’un script littéraire à la fois fonctionne dans une notation et est lui-même une œuvre. Donc dans les différents arts une œuvre est différemment localisée. […] Dans la musique, l’œuvre est la classe des exécutions concordantes avec un caractère. En littérature, l’œuvre est le caractère lui-même. Et en calligraphie, pouvons-nous ajouter, l’œuvre est une inscription individuelle. »

En d’autres termes, un écrivain rédige un texte qui en lui-même constitue une œuvre – quel que soit le système notationnel utilisé – tandis que le compositeur écrit une partition, qui n’est pas « œuvre ». La partition contient toutes les œuvres possibles, toutes les musiques qu’il est possible de générer à partir de celle-ci, mais n’est pas une œuvre en elle-même. La musique, à savoir la suite de sons organisée suivant la volonté du compositeur et jouée physiquement, constitue l’œuvre.
Bosseur propose lui aussi une définition de la partition ; il en développe même plusieurs. Il adopte un point de vue plus descriptiviste que prescriptiviste de la partition, a contrario de Goodman. Bosseur constate les utilisations du terme plus qu’il n’impose une définition précise, et émet ainsi plusieurs remarques. Nous en relèverons ici deux. La première émerge à partir de la notion de « partition verbale » :

« Vers la fin des années 1960 s’est développée une autre catégorie de partition, qui doit beaucoup à l’essor de la création collective : la “partition verbale” ; dans ce cas, la partition, écrite au moyen de mots, devient un “scénario” que les musiciens décrivent et prennent comme base de leurs actions et réactions au moment du jeu ; le recours à un texte-partition s’est révélé comme une nouvelle manière d’envisager la transmission d’un concept musical, provoquant entre les interprètes un type de communication original, moins formalisé – puisque moins codé –, faisant plus appel à la personnalité musicale de chacun que la notation traditionnelle, parce que moins préoccupé de fixer point par point chaque détail de la composition. »
La limite entre texte et partition se brouille, et Bosseur ajoute du contraste à la distinction proposée par Goodman. Le « texte-partition » arrive à une période où la recherche sur les rapports entre langage et musique est en effervescence, où les manières de décrire la musique (et les sons de manière plus générale) sont remises en question notamment à travers le travail de Pierre Schaeffer (1910-1995), qui étend immensément le vocabulaire descriptif alloué à la musique. Est-ce que le texte pourrait, dans certains cas, venir remplacer les partitions issues d’un système notationnel ? Dans un autre registre, Bosseur spécule sur la possibilité de l’existence de systèmes pouvant capter toute la profondeur d’une œuvre musicale, et permettant ainsi une transcription fidèle et parfaite. Selon lui, cette idée est chimérique, voire même dangereuse :

« chercher un système de notation généralisable à toutes les formes de communication musicale risque bien d’insinuer l’ambition d’imposer un unique système de pensée et d’analyse. »

Dans cette idée, des compositeurs comme Arthur Honegger (1892-1955) réclament davantage de contrôle et de finesse dans la transcription du son, allant jusqu’à prévoir l’abolition du musicien pour permettre de supprimer l’intermédiaire entre la pensée et la matérialisation du son. Les progrès technologiques donnèrent lui donnèrent raison ; aujourd’hui, l’informatique musicale rend virtuellement possible ce fantasme de contrôle absolu. À ce titre, peut-on considérer les différentes manifestations des logiciels de composition assistée par ordinateur (cao) comme des partitions ? Est-ce qu’un live set produit à l’aide d’un séquenceur musical logiciel comme Ableton Live, ou un patch développé avec Max/msp, peut être considéré comme une partition ? Selon le niveau de plasticité qu’on accorde à ce mot, chacun de ces exemples pourrait correspondre.
À ce stade, aucune des pistes proposées ne convient. Nous mentionnerons une dernière tentative de définition avant de poursuivre sur le sujet qui nous intéresse. Karkoschka, dont le travail sera étudié plus en détails dans la section suivante, a proposé une définition de la notation musicale qui pose peut-être moins de problèmes que celle de Goodman en le sens qu’elle est plus inclusive :

« The main purpose of musical notation is to make possible the construction, preservation and communication of more complex kinds of music. » (Le but principal de la notation musicale est de rendre possible la construction, la préservation et la communication de musiques plus complexes [traduction libre].)

Nous pouvons ainsi nous permettre d’extrapoler une définition de la partition musicale en remplaçant « notation musicale » par « partition » dans cet extrait. Bien qu’elle ne soit pas parfaite – cette proposition est en soi très ouverte –, cette description nous semble être la moins mauvaise. Pour émettre ce jugement, il faut cependant partir du principe que le compositeur est conscient du degré d’interprétabilité laissé dans son document, et que ce dernier lui convient. Finalement, nous conviendrons qu’une partition peut-être qualifiée de tel si le compositeur qui l’a écrite considère qu’elle remplit les propriétés susnommées dans la citation de Karkoschka.
Bien que cette question soit passionnante, nous n’irons pas plus loin dans son développement étant donné que celui-ci mériterait de s’étendre sur toute la longueur du présent mémoire. Avec cette rapide introduction, nous espérons avoir permis au lecteur un regard sur les problématiques incombant à ce sujet d’étude, et qu’il se joindra à notre enthousiasme pour essayer de comprendre le rôle que peut y jouer la sténographie.

ii. La typologie des systèmes de notation de Karkoschka

Erhard Karkoschka adopte une approche philosophiquement à mi-chemin entre les deux auteurs mentionnés dans la section précédente ; compositeur, chef d’orchestre et musicologue, il dresse dans son ouvrage, publié en 1966 sous le nom Das Schriftbild der neuen Musik (La Notation dans la nouvelle musique [traduction libre]) une description exhaustive de l’état de la notation musicale dans le courant de la nouvelle musique, et émet en parallèle une série de recommandations qui selon lui permettraient la conception de systèmes notationnels performants.
Indéniablement, la part la plus intéressante du travail de Karkoschka dans cet ouvrage est sa proposition de typologie des notations musicale. En plus de permettre de rapprocher certains compositeurs entre eux par leurs utilisations de la notation, sa classification aide grandement à développer une vision d’ensemble des différentes caractéristiques des systèmes notationnels utilisé par les représentants de la nouvelle musique, parmi lesquels Olivier Messiaen, Pierre Boulez, John Cage, Karlheinz Stockhausen, Iannis Xenakis, entre autres.
Karkoschka divise les systèmes notationnels en quatre catégories : les notations précises, encadrées, suggestives et graphiques . Les notations précises sont celles qui, comme le nom l’indique, retranscrivent le mieux la musique. À l’inverse, les notations graphiques sont les moins précises mais sont censées évoquer la musique plus que la codifier à travers des signes. Les quatre catégories sont ainsi une partition – au sens d’une répartition en parties – d’un spectre ayant à une extrémité l’application rigoureuse d’un système précis, et à l’autre, la suggestion par et l’évocation par des représentations plus libres. Dans la première catégorie, ce sont en général les notes qui sont inscrites. Avec les notations suggestives, on propose des relations entre les notes, ou des limites dans lesquelles évoluer. La dernière catégorie, celle des représentations graphiques, peut être beaucoup plus libre.
Le système solfégique appartient bien entendu à la catégorie des notations précises, et les sténographies musicales, nous l’avons abordé dans la section I.c., se sont efforcées à en faire partie tout autant ; ce n’est pas une condition axiomatique pour constituer un système notationnel de la musique.
L’autre facette du travail de Karkoschka qui nous intéressera ici est sa liste de prérequis à remplir afin de constituer une bonne alternative au système solfégique, la voici :

« What requirements must a new notation fulfill in order to be efficient for the present and, as far as can be foreseen, the future?
It should possess all the possibilities of traditional notation. Only technical possibilities are intended here, not aesthetic ones.
It should not go against tradition without good reason.
It should have enough new technical possibilities to be able to represent the present stage of musical thinking.
It should be capable of presenting complicated structures in a simpler form than does present-day notation.
It should have a broad, neutral basis and avoid, if possible, representing any particular style.
It should make easier the transition to individual notation forms, e.g. approximate values and musical graphics.
It should have no difficulty in being able to represent more than 12 values in an octave.
What the ear hears must be presented to the eye in such a way that two basic characteristics are taken into consideration:
the visual event must be apparent as the direct translation of the auditory event, requiring as few additional thought processes as possible.
the individual symbols and the totality of symbols must be formed on an optical basis; they must be “correct” in the visual-psychological sense. »

Comme l’avons montré dans la section I.c.2., les différents systèmes de sténographie musicale existants ne répondent pas à tous ces critères, et dérogent en particulier aux prérequis 1) et 2). Nous mentionnons le travail de Karkoschka ici principalement pour définir un cadre analytique ; ses critères se veulent très restrictifs, et les exemples que nous aborderons dans la suite de cette étude n’y répondront pas tous.


2. Les avant-gardes du xxe siècle et leurs notations musicales

Le xxe siècle vit d’un côté la naissance de l’informatique et du genre électroacoustique, et de l’autre, il fut le témoin de l’agonie de la sténographie et la mort de la sténographie musicale. En effet, rapidement après l’arrivée des premiers ordinateurs, compositeurs et musiciens comprirent les potentialités des nouveaux outils qui les entouraient. Alors que les premières tentatives d’association de la musique et de l’électronique naquirent dans les années 1920, c’est réellement une trentaine d’année plus tard, dans les années 1950, qu’on commence à inclure des ordinateurs dans le processus de création musicale. L’avènement des ordinateurs à lui seul n’était pas suffisant, mais l’électronique, tout comme les technologies de télécommunication – et par extension de traitement du signal – avançaient à une vitesse folle, et leurs découvertes se répercutaient en chaîne dans tous les domaines, la musique ne faisant pas exception. Ainsi, c’est au travers des machines originellement destinées aux télécommunications radio que les premières expérimentations de musique électronique furent réalisées. Le son des hauts-parleurs, n’étant pas limité de la même manière que ceux des instruments traditionnels mais répondant à d’autres contraintes, n’avait pas à produire une musique s’inscrivant dans le solfège.
Les acteurs de la seconde moitié du xxe siècle, à partir de ces constats, marquèrent un tournant. En France et aux États-Unis, on voit des ingénieurs-musiciens s’emparer des ordinateurs et développer des outils à l’usage des compositeurs et des musiciens. Outre-Atlantique, nous noterons en premier lieu les travaux de Max Mathews (1926-2011) aux laboratoires Bell, qui développa en 1957 le premier logiciel de synthèse sonore, Music, puis Graphic 1, une machine-logiciel précurseur de Cubase et Logic Pro. En France, l’approche sera plus conceptuelle que technique, avec en particulier Pierre Schaeffer, qui s’intéressa à la phénoménologie de la musique et qui créa en 1958 le Groupe de recherches musicales (grm) constitué principalement de chercheurs, de compositeurs et de techniciens. C’est à cette période qu’apparurent de nombreux nouveaux courants musicaux, la musique concrète de Schaeffer, la nouvelle musique théorisée par Adorno, l’acousmatique de Bayle, la spectrale de Gérard Grisey (1946-1998), la stochastique de Iannis Xenakis (1922-2001)… Toute cette richesse repoussait sans cesse les limites de la musique ; elle ne se laissait le plus souvent pas décrire par le solfège. Le système solfégique ne permettait ainsi pas de la transcrire, et les compositeurs durent trouver d’autres moyens d’écrire leur musique. Deux options s’offraient alors à eux : construire sur la base du système solfégique ou repartir de zéro et inventer de nouvelles graphies.

i. Un contexte d’innovation graphique dense

Les questionnements sur les systèmes de notation se sont intensifiés au xxe siècle avant que l’électronique n’atteigne le domaine de la musique. À ce titre, nous pouvons trouver parmi les avant-gardistes le futuriste Luigi Russolo (1885-1947), concepteur de la musique bruitiste, et notamment sa pièce Réveil d’une ville (figure 21), mais c’est avec la génération suivante que l’augmentation du nombre de signes se fit réellement sentir ; Bosseur en est rendu à trouver dangereux la quantité de travaux graphiquement novateurs, soulevant la possibilité que le visuel devienne plus important que la musique même – considération récurrente parmi les musicologues de cette époque. Il cite à ce sujet le compositeur Brian Ferneyhough (1943-) :

« le fait que tant d’œuvres des trois dernières décennies soient sans doute plus faciles à classer d’après leurs caractéristiques visuelles que selon leurs caractéristiques auditives est loin d’être un hasard. »

Les compositeurs tentent de modifier la notation de la hauteur, du temps, de l’intensité, du timbre, etc. Les multiples tentatives graphiques sont cohérentes avec le désir d’explorer de nouveaux sons, que ce soit par une utilisation originale des instruments classiques, ou avec une approche plus expérimentale et des objets inédits. Deux tendances s’opposent : la première cherche à retranscrire aussi précisément que possible une musique sans qu’aucune marge d’incertitude liée à la notation ne subsite, et la seconde consiste à laisser une part d’interprétabilité plus importante. Ces deux écoles se télescopent au sein des mêmes courants ; nous retombons ici sur la question de la définition de la partition (voir section II.a.1. Qu’est-ce qu’une partition ?). D’autres, comme Schaeffer, vont se désintéresser complètement de la question de la notation pour se concentrer sur ce qu’il considérait vraiment comme de la recherche musicale : la création d’un nouveau solfège du sonore, où peu l’ont suivi. Pour régler ces questions de représentation, Schaeffer alla au plus simple : il reprenait le système solfégique en y ajoutant des notes accompagnées de quelques phrases d’indication pour l’interprète et des séries de signes plus ou moins cryptiques. Cette approche additive est récurrente dans l’histoire de la notation ; les compositeurs partent de ce qu’ils connaissent et le tordent au besoin. C’était déjà vrai au xixe siècle, et cela l’était sûrement encore avant, mais avec le xxe siècle l’innovation musicale s’est tant éloignée du solfège que ces digressions graphiques se sont multipliées, avec des prises de libertés plus ou moins grandes. Dans Klavierstück vi (figure 22), Karlheinz Stockhausen (1928-2007) propose une partition où les tempi sont représentés sur une portée additionnelle située au dessus de la portée classique. Plus la ligne est haute et plus le tempo associé est rapide. L’interprète peut alors démontrer sa virtuosité en pouvant adapter son tempo précisément d’une mesure à l’autre. Dans la typologie de Karkoschka, ce système serait encore plus präzise que le système solfégique. Cet ajout reste relativement minime compte tenu des propositions d’autres compositeurs, qui n’hésitaient pas à proposer des modifications plus prononcées, baroques même, comme a pu le faire Sylvano Bussotti (1931-2021) dans ses partitions, avec par exemple Siciliano (figure 23). Ici, bien qu’il y ait très clairement une recherche du beau dans le visuel et dans la partition, il n’empêche que Bussotti prend comme base le système solfégique. Les notations conventionnelles s’éloignent de leur sens premier pour laisser de la place à l’interprétation du musicien. Cette partition de Bussotti en particulier irait sûrement se loger quelque part entre les notations encadrées et les notations suggestives de Karkoschka ; en effet, la pente des portées est censée indiquer des changement de tempo plus ou moins prononcés, mais rien ne semble indiquer quantitativement à quoi ils correspondent.
John Cage, en plus d’être la figure de proue de cette époque concernant la question de concevoir la musique, n’hésita pas à s’aventurer lui aussi dans des représentations expérimentales de la musique. À cet égard, il fut peut-être l’un des compositeurs les plus radicaux en termes de partition. Cage se désolidarisa complètement du solfège pour penser le son plus largement, et pour cela, il devait se séparer du système solfégique. N’importe quel amateur de son peut s’approprier ses Variations ou Cartridge Music (figures 24 et 25) une fois que leurs quelques règles aient été exposées. Ses partitions n’ont rien de précis, elles guident simplement l’interprète dans un registre musical dont les limites très lointaines ont été inscrites par le compositeur. Dans ces partitions, nous retrouvons ce que Karkoschka qualifiait de graphiques musicaux. Poussée à l’extrême, cette conception de la notation que Cage partage avec Boulez peut résulter sur des productions graphiques surprenantes. David Ireland (1930-2009), en hommage à l’auteur des Variations, proposa une série de partitions dont une que nous reproduisons ici avec la figure 26 et qui présente des qualités graphiques étrangement proches des sténographies occidentales. Pour réaliser cette partition, Ireland jeta des bouts de fils et d’élastiques sur des plaques de gravure et les imprima sur du papier à musique. La lecture de l’œuvre se fait à l’appréciation de l’interprète. En soi, rien n’empêche l’artiste de qualifier son œuvre de partition, et nous pouvons sans mal, à l’instar des partitions graphiques de Cage reproduites ici, les ranger dans la catégories des graphiques musicaux.

ii. Le genre électroacoustique : la technologie à tous les étages

À partir des années 1950, les technologies informatiques élaborées durant la première moitié du siècle ont pu être suffisamment développées industriellement pour être mises à portée des ingénieurs, compositeurs et musiciens. Les protagonistes de l’époque voulurent une tabula rasa ; un rejet du passé, et ils y sont en partie parvenu.
En 1998, alors que le temps écoulé permettait un certain recul historique sur les avant-gardes musicales du milieu du xxe siècle, Pierre Couprie tenta de cerner les limites de ce que représente la musique électroacoustique, et en arriva à la conclusion que la musique électroacoustique, par les multiples dispositifs scéniques qu’elle admet, la myriade d’expériences musicales (comme la musique concrète ou la musique en temps réel), et la richesse lexicale qu’elle invoque (plusieurs termes sont utilisés pour parler d’un même phénomène), ne pouvait être circonscrite à une « musique », mais constituait un « genre » à part entière. Cette débâcle terminologique peut se résumer ainsi : l’électroacoustique fédère énormément d’artistes et regroupe énormément d’œuvres.
L’informatique musicale fut rendue possible lorsque l’on comprit comment transformer un signal analogique en un signal numérique. À partir de cette base, il est possible d’analyser le son entrant dans un micro mathématiquement ; les différentes oscillations de l’air étant converties en des séries numériques. En sortie, on était maintenant capable de convertir un signal numérique en une série de positions pour la membrane d’un haut-parleur. Les bandes magnétiques utilisées par les ordinateurs pour enregistrer les données numériques venaient déjà à l’origine du monde de la musique ; tout est bon. L’analyse est rendue possible : on peut ainsi décomposer un son en une combinaison de fréquences, et donc visualiser le timbre. On parle du spectre d’un son, rendu discernable par un spectrogramme. Schaeffer fut au centre de ces études, et le timbre, avec d’autres caractéristiques du son, décrocha une place qu’il n’avait jamais occupée auparavant : une place centrale. Schaeffer pensa le son sous toutes ses coutures, et selon Laurent de Wilde, Schaeffer se mit à le « réinventer […] de toutes les façons possibles et imaginables ».
À l’opposé de l’analyse, la production musicale est elle aussi chamboulée. Les travaux du mathématicien Joseph Fourier (1826-1830) furent mis à contribution pour la synthèse sonore. Rapidement, le catalogue de sons qu’il fut possible de générer devint infini pour finir par coexister aujourd’hui avec les synthétiseurs analogiques. La synthèse analogique marqua ainsi le départ de la musique électronique, un pan très étendu du genre électroacoustique. L’invention du transistor permit le développement des ordinateurs et rendu possible le travail de Mathews au sein de l’équipe d’Acoustique et de Recherche comportementale des Bell Labs, qui possédait alors un ibm 704, un supercalculateur juste assez puissant pour développer les premiers outils de synthèse numérique. S’en suivra une décennie d’expérimentations en tout genre, qui posèrent ainsi les bases de la production informatisée de la musique.
L’énumération de ces quelques points clés de l’histoire de l’informatique musicale se recoupent en un même caractère commun : chacune de ces innovations découle de la précédente, et ce, dans une temporalité très réduite. Le xxe siècle n’avait pas le temps d’attendre, pour le meilleur et pour le pire. Dans la section suivante, nous essaierons de nous consacrer au meilleur.

iii. L’upic et la philosophie de Xenakis

Comme mentionné en préambule de cette section, laboratoires et institutions se spécialisant dans l’informatique musicale se mettent à germer un peu partout au début des années 1950, avec à leur direction ou parmi leurs membres des personnages déterminants comme Mathews, Schaeffer, ou encore Xenakis avec son cémamu. Ce dernier nous intéressera particulièrement, notamment avec son projet principal : l’upic. Cyrille Delhaye et Rudolphe Bourotte y consacrèrent un article en 2014, voici comment ils y introduisent le projet de Xenakis :

« c’est seulement en 1977 que naît le prototype d’une machine hybridant le dessin, la synthèse sonore et la musique : elle est baptisée upic (Unité Polyagique Informatique du cémamu). Le suffixe “agogique” [du grec ancien ἀγωγή (agôgê, conduite, mouvement musical)] évoque tous les paramètres expressifs de la notation musicale. En y accolant le préfixe “poly” Iannis Xenakis fonde un néologisme qui ouvre un champ de liberté à de multiples processus compositionnels, en faisant du dessin le principal vecteur de la composition musicale. L’upic permet ainsi de concevoir par le dessin des structures musicales, des enveloppes, des dynamiques, des sons, des formes d’ondes, etc. »

À partir d’une simple table, d’un stylo adapté et d’une interface permettant la synthèse du son, cette machine permettait à quiconque de composer une musique en la dessinant. La hauteur du son est accessible sur l’axe des ordonnées tandis que le temps est représenté sur l’axe des abscisses. Avec cet outil et au travers des ateliers d’initiation à l’upic – qu’il entame en 1980 et qu’il poursuivra aux quatre coins du monde –, Xenakis pensait pouvoir servir un intérêt plus grand, qu’il décrit en 1982 :

« Pourquoi tous ces déplacements ? Tout d’abord pour mobiliser le public spécialisé et non spécialisé sur le fait que la composition musicale peut être mise à sa portée. […] puis pour sensibiliser sur autorités locales et les Ministères sur les énergies intellectuelles profondes et intenses que le public de la rue libère au contact de l’upic d’une façon aussi naturelle que soutenue. […] En fait, c’est un miroir de notre monde individuel psychique et mental puisqu’elle crée un dialogue actif entre le moi de l’imagination et le moi de la critique et de la décision. Si les autorités locales et les ministères comprenaient ce besoin universel, ils pourraient trouver les moyens pour le satisfaire. […] c’est donc dans la perspective d’une lutte, d’une croisade contre l’alphabétisation musicale que se placent les séries de démonstrations dans les villes, en France et à l’étranger. »

L’apprentissage de la musique, l’émancipation des plus jeunes issus de milieux dans lesquels l’accès à la connaissance est moins aisé, des non-voyants (figure 27)… Xenakis veut permettre à chacun l’opportunité de faire de la musique ; il veut convaincre les gouvernants et les intellectuels qu’il s’agit d’un un art accessible à tous. D’après lui, ce projet est rendu possible grâce au contexte technologique dans lequel il s’inscrit. Lors d’un entretien avec Bosseur, il déclare :

« Quand j’ai commencé à dessiner pour faire Metastasis [(figure 28)], j’ai pensé que si je pouvais avoir un système qui puisse traduire l’idée musicale directement sans avoir à me casser la tête à écrire des notes, tout simplement… C’est une idée qui est restée comme ça pendant des années jusqu’à ce que la technologie puisse me prêter secours. »

Cette technologie dont il attendait la démocratisation se révéla être révolutionnaire : Xenakis avait besoin d’un dac, un digital to analog converter, ou en français convertisseur analogique numérique. Cet outil, qui n’a l’air de rien et est pris pour acquis aujourd’hui, est ce qui permet l’existence de l’informatique musicale. Sans ce dernier, aucune onde sonore ne pourrait être reçue ou émise d’un ordinateur. La place de ces technologies est au cœur de la pensée utopique de Xenakis, qui espère, via l’upic et la création des mondes sonores qu’il rend possible, permettre aux utilisateurs de prendre conscience de la « science physique sous-jacente » des machines. Nous n’avons pas utilisé le terme « utopique » ici par hasard : c’est bel et bien le mot le plus adapté pour penser la philosophie de Xenakis. Son approche est sociale et scientifique, et s’inscrit dans une volonté humaniste qui motiva toute son œuvre.
Il paraît inexcusable ici de ne pas au moins pointer du doigt le parallèle que nous pouvons faire entre l’idéologie qui motive Xenakis et celle qu’embrassaient Duployé et Pitman en leur temps (voir la section I.b.2.i.). Chacun d’entre eux rêvaient de permettre l’émancipation par l’alphabétisation du plus grand nombre. Tous les trois accordaient une grande importance à la pédagogie et à la publicisation de leur projet par le voyage.


3. De la ligne à la note : la notation musicale au xxie siècle

Nous ne nous attarderons pas plus longtemps sur les notations musicales des siècles révolus. Le xxie siècle a déjà rencontré une production très riche aussi bien du point de vue des outils que de celui des innovations graphiques ; c’est à ce dernier que nous nous intéresserons dans cette section.
Les découvertes technologiques du xxe siècle ont eu le temps de se développer et de se démocratiser, si bien qu’il est devenu quotidien d’entendre se gargariser les technophiles sur des comparaisons entre les puissances des machines de la nasa des années 1960 et les smartphones que nous portons chacun – ou presque – dans nos poches. Ce saut quantitatif permit d’accueillir le développement de nouveaux paradigmes d’interactions humain-machine, et la puissance nouvellement acquise des ordinateurs rendit virtuellement possible la production de tout son imaginable. Avec ces innovations aussi bien matérielles que logicielles, la notation musicale a pu être repensée : la voie conceptuelle ouverte par les compositeurs du xxe siècle a pu être réaliser son potentiel avec l’aide des nouvelles technologies.
Dans cette section, nous contextualiserons l’environnement créatif dans lequel s’inscrit notre démarche. En d’autres termes, nous résumerons brièvement quelles sont les questions les plus abordées par les penseurs de la notation musicale du début du xxie siècle. Il s’agira d’abord de comprendre le cadre technologique de la production de partitions non solfégiques, puis d’entrevoir ses conséquences sur les interactions entre les utilisateurs et les machines du point de vue de la notation. Enfin, nous aborderons deux types de partitions qui ont pu se développer grâce aux progrès technologiques : la partition animée et la partition en temps réel. Grâce à cette mise en contexte, nous disposerons des outils théoriques nécessaires à l’argumentation de notre thèse, à savoir que la sténographie musicale détient un potentiel important au vu de l’état de la notation musicale aujourd’hui. Ces arguments seront déroulés par la suite dans la section II.b.

i. Un écosystème logiciel et matériel

La musique ne s’est jamais autant reposée sur les technologies musicales qu’aujourd’hui. Que ce soit au niveau des modes de diffusion ou de production, les outils informatiques et électroniques sont partout. Alors qu’il y a cent cinquante ans la musique exclusivement acoustique était la seule possible, aujourd’hui, elle est devenue très largement minoritaire. Cette considération est aussi vraie pour la composition et l’écriture de la musique ; le solfège n’est plus un prérequis inaliénable à la création musicale quand un ordinateur est à portée de main. Chacun peut se procurer un logiciel de composition assistée par ordinateur et produire sa propre musique sans connaissance préalable. Dans cette section, nous nous intéresserons en particulier à quelques logiciels et machines permettant d’allier cao et écriture manuscrite.
En effet, si la cao s’est développée, c’est parce qu’elle en a eu la possibilité au travers du mode d’interaction le plus accessible et le plus évident : celui du clavier et de la souris. Pour que celles-ci restent intuitives, les interfaces utilisateur des logiciels musicaux ont été construites sur le principe du skeuomorphisme (du grec ancien σκεῦος, skeuos, ustensile, enveloppe corporelle), c’est-à-dire qu’elles ont imité visuellement le fonctionnement des instruments et machines dont elles reproduisaient les sons. Ainsi, les langages de programmation comme Max/msp ou Quartz Composer découlent directement de la structure des synthétiseurs modulaires (figures 29 et 30). Pareillement, les logiciels de montage sont inspirés des coupes et collages du montage sur bande. L’écriture manuscrite, elle, n’était pas une technologie transposable aussi naturellement sur les ordinateurs ; le texte est communiqué à l’ordinateur grâce au clavier, et non pas dessiné à la souris. L’intégration de ces mouvements dans nos interactions avec les ordinateurs, à savoir le dessin assisté par ordinateur (dao), est toujours problématique : ni les pavés ni les écrans tactiles ne se révélèrent être une solution à cette question. Pour arriver à des résultats convenables, il est nécessaire d’ajouter des composantes plus ou moins coûteuses selon le niveau d’ergonomie souhaité (les tablettes graphiques), ou alors de se passer du tracé à main levée et générer les courbes autrement (principalement avec les courbes de Bézier).
Ce contexte n’est pas favorable au développement de systèmes de notation musicale ; par ailleurs, on notera l’absence presque totale du système solfégique dans ces interfaces. Les différentes gammes se sont normalisées en fréquences. On ne voit pas de la par défaut (ou à l’anglaise, de A) : la notation symbolique est très souvent remplacée par son homologue fréquentiel visualisable, plus adapté aux machines numériques – en l’occurrence 440 Hz pour un la 440. Ce passage au nombre est la manifestation des nouvelles possibilités musicales offertes par les progrès technologiques : il permet une dissociation de ces logiciels du solfège, du système solfégique, et au passage, de ses variantes notationnelles régionales. La production de musique s’est universalisée, et Bosseur souligne l’inadaptation du système solfégique :

« L’expérience de l’électronique a certainement compté pour beaucoup dans cette insistance sur la visualisation du phénomène acoustique, le système solfégique se révélant encore plus inapte à représenter les intentions compositionnelles liées aux opérations électro-acoustiques que les recherches de nouveaux modes de jeu vocal ou instrumental. »

Aujourd’hui, la plupart des logiciels de cao se passent donc d’une médiation par la notation musicale : l’environnement de travail, une fois préparé et paramétré, permet de générer la musique en temps réel puis de s’adapter instantanément aux ajouts ou aux modifications de l’utilisateur. Ce paramétrage peut ainsi prendre plusieurs formes, et certains tentèrent de l’opérer via le dao. Un grand nombre d’initiatives allant dans ce sens et que nous avons pu isoler proviennent d’une nouvelle génération de chercheurs rassemblés dans un réseau international en particulier : le tenor Network. En France, cette recherche est principalement menée depuis le laboratoire RepMus, par lequel nombre des membres du tenor Network sont passés. Sans rentrer dans les détails de ces logiciels, nous essayerons ici de garder une vision générale de ceux-ci en citant des exemples et en invitant le lecteur à aller visiter les liens référencés s’il souhaite approfondir la question. Dans cette énumération, nous effectuerons le distinguo entre les logiciels effectuant une synthèse du son à partir de la partition créé dans le logiciel avec la marque s tandis que nous marquerons du sigle ns les logiciels servant uniquement à la création de partition. Cette distinction est importante car elle souligne le cas d’utilisation sur lequel se penchèrent les développeurs du programme ; l’absence de synthèse implique une pratique de la partition différée, et souligne l’importance accordée à la phase d’écriture. Dans la même idée, nous marquerons avec la marque m les logiciels permettant de dessiner les courbes à main levée, tandis que les autres porteront la marque nm.
Premièrement, il est intéressant de noter qu’une importante part de ces programmes est basée sur les mêmes langages de programmation spécialisés ; Max/msp, openFrameworks et OpenMusic. Ces trois langages peuvent être rassemblés sous une même intention de base : rendre le code informatique accessible aux artistes. En effet, ce sont des langages de haut niveau (c’est-à-dire construits par-dessus plusieurs couches d’abstraction) qui permettent ainsi de rapidement obtenir des prototypes viables. Nous pouvons ranger dans cette catégorie les projets comme Symbolist (s, nm), les notations génératives de David Kim-Boyle (s, nm), et l’ensemble des partitions animées de Ryan Ross Smith (ns, nm).
Deuxièmement, il existe aussi des projets se détachant de ces langages, ce qui leur permet d’exister sous la forme d’exécutables autonomes. Nous noterons upisketch (s, m), une version logicielle de l’upic développée par Rodolphe Bourotte au cix, HighC (s, m), Music Sketcher (ns, m) développé par ibm au début des années 2000 et pensé en priorité pour les tablettes graphiques, et enfin le Decibel ScorePlayer (ns, m), qui permet de générer virtuellement toutes les partitions possibles des Variations de Cage. Ce dernier est d’autant plus intéressant par le fait qu’il soit distribué sous la forme d’une application pour iPad, mais aussi avec un connecteur à Max/msp. En plus d’essayer de proposer une solution aux problèmes de dao que nous avons mentionnés plus haut dans cette section, le Decibel ScorePlayer met à la disposition des utilisateurs une grande marge de manœuvre en donnant accès à une forme d’api (application programming interface, ou en français interface de programmation d’application).
Dernièrement, il existe un dernier type de projets à cheval entre informatique musicale et notation : les interfaces matérielles. Nous n’avons trouvé au cours de nos recherches qu’un seul projet répondant à ces critères. Il s’agit d’InkSplorer, développé principalement par Jérémie Garcia lors de sa thèse, qui a cherché des moyens de réintégrer le papier dans la pratique de la composition en partant de l’hypothèse que le papier et l’esquisse jouent un rôle décisif dans le travail du compositeur. Il cite Jean-Baptiste Thiebaut à ce sujet :

« the use of pen and paper can play a key role in the development and refinement of musical ideas [whereas] existing technology does not support similar functions, but rather encourages a premature commitment to the realization of a piece. » (l’utilisation du papier et du crayon peut jouer un rôle clé dans le développement et l’amélioration des idée musicales, [tandis que] les technologies existantes n’ont pas ces fonctionnalités, mais encouragent plutôt la production d’une œuvre prématurée, sans étape intermédiaire [traduction libre].)

À partir d’une feuille de papier précisément tramée et d’un stylo équipé d’une caméra miniature, Garcia a développé un dispositif permettant d’extraire toutes les coordonnées du mouvements d’un scripteur dans le temps. Grâce à cette approche, l’utilisateur peut écrire avec la même aisance que sur n’importe quel autre papier : il résout ainsi le problème récurrent du dao, fil conducteur de la recherche de Thiebaut.
Ces différentes approches montrent qu’il existe un terrain où la notation musicale manuscrite peut évoluer aux côtés des technologies contemporaines, les outils de Garcia ont notamment été utilisés en conditions réelles par le compositeur Philippe Leroux dans son œuvre électronique Quid sit musicus ?. Cet exemple dénote aussi d’un intérêt envers le pont qui relierait d’un côté la matérialité du papier pour l’écriture et de l’autre le potentiel de l’informatique musicale contemporaine. Il s’agira de voir sous quelles modalités ces notations peuvent être utilisées ; ce sera l’objet des deux sections suivantes, qui s’intéresseront respectivement à cerner les notions de partition en temps réel et de partition animée.

ii. Partition en temps réel

La partition en temps réel est une notion principalement développée par le compositeur allemand Gerhard E. Winkler (1959-). Il définit la partition en temps réel ainsi :

« I brought together both concepts, – interactive signals of the musicians to a computer, and the generation of the score in realtime due to the state of a dynamic system, which is open to interactive signals – and created the concept of the so-called Realtime-Score, a notion I used the first time in 1994. » (J’ai associé ensemble deux concepts – les signaux interactifs des musiciens à l’ordinateur, et la génération d’une partition en temps réel à partir de l’état d’un système dynamique, qui est ouvert aux signaux interactifs –, et ai créé le concept ainsi nommé la Partition en Temps-réel, une notion que j’ai utilisé pour la première fois en 1994 [traduction libre].)

Winkler délègue donc l’écriture de la partition à la machine. L’ordinateur, n’évoluant pas sur la même échelle de temps que nous, est capable physiquement d’« écrire au rythme de la musique », ce que nous n’avons a priori – nous, humains – jamais réussi à faire avec la sténographie musicale. Il imagine cette interaction comme un partenariat avec l’ordinateur, chacun s’influençant au sein d’une boucle de rétroaction comme cela peut se faire au jazz. Les musiciens jouent, la machine écoute, produit une partition en fonction de ce qu’elle entend, et les musiciens jouent la partition générée, etc. Bien qu’en théorie, les partitions en temps réel peuvent rentrer dans la catégorie des notations précises de Karkoschka, celles-ci semblent en pratique presque toujours osciller entre les trois autres catégories, des notations encadrées aux graphiques musicaux. La réflexion de Winkler, ce n’est pas étonnant, a germé a l’ircam, fief de Boulez ; la partition n’a pas vocation à fixer la musique, elle la guide, interagit avec elle, et remet l’interprète au centre de la performance. Il conclut son article avec poésie, en essayant d’anticiper les remarques sur la place de compositeur qu’on pourrait lui adresser :

« The role of the composer as “author” rests unchanged, also in the new context, but it shifts from the “builder”, the “architect” to the creator of a set of “potentialities”, comparable to a gardener, who plants “nuclei” or germs, and watches them grow, depending on influences from the environment, in this or that way. All versions are welcome. » (Le rôle du compositeur comme « auteur » reste inchangé, aussi dans ce nouveau contexte, mais il se déplace du « constructeur », ou de l’« architecte », à celui du créateur d’un ensemble de « potentialités », comparable à un jardinier, qui plante des « nucléi », ou des germes, et qui les regarde grandir selon les aléas de l’environnement, de telle ou telle manière. Toutes les versions sont bienvenues [traduction libre].)

En partant de versions allégées de sténographies musicales déjà existantes, qui n’iraient pas essayer de remplir tous les critères énoncés par Karkoschka mais en cherchant à transcrire seulement certains aspects de la musique (hauteur, intensité, timbre, etc.), il serait possible d’imaginer un dispositif de notation en temps réel où à la place de la machine seraient des humains. Cette boucle de rétroaction, en plus de venir influer sur et d’être influencée par la musique, permettrait la scripturalisation en temps réel d’une partition, et une manière de « jouer » de la musique dans un mode possiblement plus accessible à chacun. Nous développerons cette idée plus en détails dans la section II.b.2.ii. Scripturalisation performative de la musique.

iii. Partition animée

Avec une approche différente, des chercheurs et compositeurs comme Cat Hope et Ryan Ross Smith s’attellent aussi à la question des rapports entre ordinateurs et partitions. Eux arrivent par un angle différent, qui, comme nous l’avons vu dans la section II.a.3.i. Un écosystème logiciel et matériel, n’impliquent pas de synthèse du son en parallèle de la rédaction de la partition. Pour Hope et Ross Smith, l’écriture de la partition animée est antérieure à son exécution ; elle se rapproche d’une conception de la musique à la table. Hope la définit en agrégeant plusieurs citations :

« What is animated notation? Animated notation, or animated score, has been defined as:
“Any score that contains perceptibly dynamic characteristics that are essential to the symbolic representation of the compositional idea” (Ross Smith);
“Abstract graphics (avoiding images, symbols or pictograms with an inherent meaning) are put into motion for music notational purposes and manifest as fixed media” (Fischer);
and as a type of “screen-score” that “can be one or more photographic images, film or a gui [graphical user interface]… usually put into motion by way of software on a computer.” (Hope and Vickery). »
En d’autres termes, la partition animée est une partition en mouvement constituée de signes graphiques mobiles ou non, mais sur un support fixe, dans le sens où celui-ci restera inchangé d’une exécution à l’autre. Ce support peut être une vidéo, un programme informatique, ou une feuille de papier. Pour illustrer cette définition, nous recommandons vivement au lecteur d’aller visionner quelques-unes de ces notations animées ; la capture que nous reproduisons ici (figure 31) ne pouvant, par définition, pas constituer une documentation suffisante pour une telle notation. Nous pouvons cependant, grâce à cet instantané de Black Tide de Hope, extraire quelques caractéristiques récurrentes des partitions animées. La barre verticale présente sur la capture est un outil graphique régulièrement emprunté par les compositeurs de partitions animées : elle permet d’indiquer ce qui doit être joué à l’instant t. Dans cette partition précisément, les signes défilent de la droite vers la gauche, et sont comme « scannés » par les musiciens au moment où ils passent sous la barre.
Bien que cela ne soit pas une condition comprise dans la définition de la partition animée, les partitions sont parfois exposées très clairement à l’audience, qui peut alors lire le document de la même manière que les musiciens. Roth Smith, lors de la présentation à l’ircam de sa Study 56, a pris au hasard dans le public les personnes qui allaient être l’instant d’après ses interprètes ; compréhensible par tous, les quelques règles souvent idiosyncratiques à chaque partition sont explicables en quelques phrases. Ce type d’exhibition des partitions n’est cependant pas la norme : Hope explique qu’elle ne montre généralement pas ses partitions animées au public. Selon elle, elles détournent l’attention du spectateur de la musique vers le visuel, et gâchent la beauté et le mystère qui entourent la musique. Selon elle toujours, la notation est faite pour partager des informations à l’interprète. En déclarant cela, Hope se positionne – et positionne par la même occasion les autres compositeurs de partitions animées à leur insu – par rapport à l’écueil qui guette les inventeurs de systèmes notationnels de la musique : celui de faire prévaloir le visuel sur le sonore.
Hope semble cependant éluder dans cet article une dimension importante des partitions : leurs aspects ludique et pédagogique. Xenakis l’avait compris, et c’est au moins en partie pour cela qu’il sacralisait moins le son par rapport au visuel. Il comprenait l’importance de la métaphore synesthétique que l’on peut faire en suivant la partition tout en écoutant la musique.


b. Applications et avantages de la sténographie
musicale au xxie siècle

1. Dans l’apprentissage de la musique

L’apprentissage de la musique n’est pas réputé comme étant à la portée de tout un chacun. Au contraire, il est souvent associé à un certain élitisme, à la musique classique, et est souvent lié dans les imaginaires à des formations longues, l’enseignement du solfège au plus jeune âge, etc. Certains tentèrent de s’opposer à cette vision savante de la musique ; nous avons déjà abordé à ce sujet le cas de Xenakis. Dans cette section, il sera question d’approfondir les liens pouvant être tissés entre sténographie et pédagogie. Ainsi, nous repartirons du travail réalisé avec l’upic, et de la conception de la musique de Xenakis et de Cage, et comment leur approche diffère de celle des pédagogues de la musique classique. Ensuite, nous nous attarderons sur comment se lit la sténographie et verrons que la part d’interprétabilité des sténogrammes peut être féconde. Puis, nous développerons comment une prise en compte purement phonétique de la graphie peut aider l’utilisateur d’un système sténographique à se réapproprier la voix dans un rapport différent de celui qu’il a habituellement au langage. Par ces deux exemples, nous verrons en quoi la sténographie, bien qu’elle soit fondamentalement une technologie de l’écriture, reste éminemment liée au son, faisant d’elle un outil de choix pour retranscrire la musique.

i. La pédagogie et le jeu

Comment abattre les barrières culturelles et sociales qui régissent l’accès à la connaissance musicale ? Cette question, comme évoqué dans la section II.a.2.iii. L’upic et la philosophie de Xenakis, est la quête principale qui motiva l’entreprise de Iannis Xenakis. Nous nous placerons ici dans son héritage. En effet, Xenakis a réussi à rendre accessible la production de la musique en prenant le contre-pied des outils permettant la génération de sons ; Xenakis n’a pas eu recours aux instruments de la musique classique (e.g. le piano, la flûte), dont l’accès à la maîtrise est souvent régie par la connaissance du solfège. Plutôt, Xenakis a fondé son projet sur l’hypothèse qu’il faudrait passer outre l’accoutumance à un instrument et l’apprentissage d’un système particulier. Il a fait le pari d’utiliser un couple d’objets auquel chacun est habitué depuis le plus jeune âge, à savoir la table et le crayon. Ce cadre, agnostique en ce qui concerne le système d’écriture, plus proche du dessin donc, permettait l’émancipation de toute connaissance théorique préalable. L’upic s’apprivoise de manière empirique, en essayant et en rectifiant. Surtout, elle se découvre par le biais d’un outil avec lequel l’utilisateur n’a pas à se familiariser : le crayon, déjà bien connu. La sténographie présente les mêmes avantages. Bien qu’elle ne soit pas désolidarisée de la notion de système – elle ne peut être que système –, son apprentissage est beaucoup plus accessible que celui du solfège. Lors de notre premier atelier découverte de la sténographie, les participants ont très rapidement pris leurs repères dans le système Duployé et ont expérimenté avec engouement l’écriture et la lecture de leurs sténogrammes respectifs. Ce n’est pas un hasard si Xenakis, Isaac Pitman, l’abbé Duployé, Aimé Paris et tant d’autres ont tous choisi l’itinérance pour partager et faire connaître leurs systèmes : la sténographie, comme l’upic, sont des vecteurs de savoir importants, facilitent le contact, et ne nécessitent que très peu de moyens pour être mis en place et animer des heures d’atelier.
Dans un autre registre, John Cage, parmi d’autres, s’interrogea sur la manière d’enseigner la composition. Alors qu’il était professeur à la New School for Social Research de New York à la fin des années 1960, il propose aux étudiants de tout type de formation, musicale ou non, de venir assister à son cours. Il n’y était pas question de solfège, le contenu du cours était accessible à chacun. Le programme élaboré par Cage est le suivant :

« Experimental music, a course in musical composition with technological, musicological, and philosophical aspects, open to those with or without previous training. Whereas conventional theories of harmony, counterpoint, and musical form are based on the pitch and frequency components of sound, this course offers problems and solutions in the field of composition based on other components of sound: duration, timbre, amplitude, and morphology; the course also encourages inventiveness. »

Cage est l’un des héritiers directs de Russolo ; selon lui, tout son peut être considéré comme musique. Le sacré ne réside plus dans la musique savante, mais dans les sons du quotidien. Les questions de rythmes, de hauteurs, d’harmonie, n’ont ainsi plus la même importance et sont placés au second plan. Il pensa son cours comme un atelier destiné à des étudiants avec un niveau de connaissance musicale allant de débutant à modéré. Son cours s’appela d’abord « Musique expérimentale » avant d’être renommé en 1968 « Composition expérimentale » ; Cage voulait se libérer de la lourdeur de l’héritage historique lié au terme « Musique » tout en mettant en exergue le fait qu’il planifiait d’aborder des sujets plus vastes. L’écriture occupa une position clé dans son enseignement. Il entretenait un rapport « mutuel » avec ses étudiants ; la New School se voulait un endroit où l’exploration était possible, où l’on apprenait en faisant et en discutant plutôt que dans une relation unilatérale allant du professeur à l’élève. Bien que Cage ne s’adressait pas du tout aux mêmes types d’audiences que Xenakis avec les ateliers upic, il est clair que des modes alternatifs de sensibilisation à la musique existent, et que la composition et l’écriture peuvent y prendre une place centrale.
Pour que leurs pédagogies respectives puissent être reçues par les participants, elles devaient capter leur intérêt. Le format participatif devait suggérer chez les étudiants une envie spontanée à s’impliquer, et donc à créer. Pour arriver à cet objectif, Xenakis et Cage avaient recours à mécanisme commun sous des modalités différentes : la notion de jeu. L’upic et les partitions graphiques de Cage ont pour similarités leur rapide prise en main et un degré de liberté important circonscrits par quelques règles facilement assimilables.
Comment est-ce que le jeu survient dans la pratique de la sténographie ? Notons déjà qu’elle partage avec l’upic et les partitions de Cage les quelques caractéristiques évoquées ci-dessus, mais surtout, la dimension ludique de la sténographie réside en ses capacités inhérentes à compresser l’information. Qu’il s’agisse de musiques ou de paroles, du système de Baumgartner (figure 20) ou de celui de Duployé (figure 2), pour pratiquer la sténographie, il faut chiffrer l’information quand on écrit et la déchiffrer quand on lit. Ces séries de compressions et de décompressions, de chiffrements et de déchiffrements, peuvent s’opérer à des difficultés variables selon le système utilisé. Dans les ateliers upic, l’aspect ludique de l’instrument de Xenakis provenait de la bijection claire opérée entre du tracé du dessin vers la génération du son. La sténographie, quant à elle, est surjective ; plusieurs mots en écriture usuelle peuvent résulter sur le même sténogramme. Le caractère ludique de la sténographie provient de ce manque de clarté et de cette polysémie, élucidés par le contexte de la phrase (musicale ou non). Bien que la dimension ludique de la sténographie n’ait pas été totalement omise par les sténographes du xixe siècle, celle-ci n’a, nous le croyons, pas exploité tout son potentiel. Bien sûr, pour vérifier cette hypothèse, il s’agira d’élaborer un protocole et de le mettre à l’épreuve en conditions réelles. C’est l’un des objectifs que nous nous sommes fixés pour les ateliers découverte de la sténographie, et que nous continuerons de faire évoluer au fur et à mesure de notre exploration.

ii. La sténographie : une approche éminemment sonore

Nous avons retracé dans la première partie de ce mémoire l’histoire de la sténographie de la parole et de la sténographie musicale. Comme le précise Gardey dans la définition qu’elle donne de la sténographie, il s’agit avant tout d’une technologie de scripturalisation du son. Elle englobe dans son idée aussi bien les langues que la musique. Dans la suite de notre développement, nous avons vu en quoi consistaient les trois principaux paradigmes abréviatifs mis en place pour améliorer la vitesse d’écriture des différents systèmes sténographiques. Les abréviations phonémiques nous intéresserons particulièrement dans cette section. En effet, si les abréviations graphiques et morphémiques tiennent principalement de l’apprentissage par cœur, les abréviations phonémiques ne relèvent pas des mêmes mécanismes cognitifs. Bien que l’apprentissage de la phonétique dans la lecture de l’écriture usuelle repose sur la technique du par cœur, nous pouvons cependant nous appuyer sur d’autres indices pour associer les graphies des mots à leur sens, comme les relations sémantiques et étymologiques, ou les morphèmes. Nous l’avons vu dans la section I.a.3.ii. La question de la lisibilité, les abréviations phonémiques de la sténographie aplanissent tous ces indices et rendent la sténographie globalement moins lisible. 
Lorsqu’une personne entreprend la lecture d’un sténogramme, elle doit bien sûr commencer par considérer le contexte déterminé par les mots précédents et par la thématique du texte. Une fois ce contexte déterminé, la lecture du sténogramme s’effectue phonétiquement à partir des signes sténographiques – qui permettent souvent de retranscrire un nombre moins important de phonèmes de l’écriture usuelle. Se produit alors une phase de tâtonnement, vécue par chacun régulièrement lors de l’apprentissage de la lecture, quand le lecteur doit essayer de faire correspondre le contexte du mot à l’ensemble de mots qu’il connaît et qui correspondent à la description phonétique transcrite sténographiquement. À la fin de cette phase, le lecteur passe mentalement d’un signifiant phonétique à un signifié conceptuel. Lorsque la lecture du système usuel est maîtrisée, cette étape de vague se raréfie, pour devenir très occasionnelle ; elle survient par exemple lorsque l’on est confronté à des écritures manuscrites difficiles à lire, des mots rarement rencontrés, ou encore lorsqu’on apprend à lire une langue qu’on sait déjà parler. La plupart du temps, la lecture d’un mot se manifeste mentalement sous la forme de ce que Ferdinand de Saussure (1857-1913) qualifia d’« image acoustique ». Ingold résume le concept ainsi : 

« Entendu dans un sens purement physique ou matériel, le son ne peut donc par conséquent pas appartenir à la langue. Il n’est, dit Saussure, “qu’une chose secondaire, une matière qu’il met en œuvre”. Il n’y aurait donc dans le langage pas de sons à proprement parler, mais uniquement ce que Saussure appelle des images acoustiques. Alors que le son est physique, l’image acoustique, elle, relève de la psychologie – elle est l’“empreinte” psychique de ce son sur la surface de l’esprit. »

L’image acoustique correspond donc à la représentation psychique d’un mot. Alors que Saussure l’associe à une forme intériorisée du son, Ong apportera une critique à cette dernière hypothèse. En effet, selon le philosophe, les cultures de l’écrit ont tellement imprégné nos rapports à la langue qu’il est pour lui impossible de désolidariser mentalement un mot de sa graphie ; l’image acoustique d’un mot ne peut pas exister sans l’avoir vu préalablement à l’écrit, elle intègre des caractères. Il développe : 

« L’écriture nous fait assimiler les “mots” à des choses car nous voyons les mots écrits comme des traces visibles destinées à ceux qui les déchiffre : nous pouvons voir et toucher de tels “mots” inscrits dans les textes et les livres. Les mots écrits sont des résidus. La tradition orale ne possède aucun résidu ou dépôt semblable. »

Ong argumente que la notion d’image acoustique ne peut pas exister dans les cultures orales ; pour ces dernières, la langue n’est pas faite de mots, mais de sons. Il soutient l’idée que ces cultures n’auraient pas de mots en dehors des sons : les sons sont les mots. Ainsi, il n’existerait pour eux aucune différence entre chant et discours, qui seraient ainsi confondus. Gertrude Stein (1874-1946) toucha du doigt, si on peut dire, le mécanisme cognitif décrit par Ong :

« I don’t hear language, I hear tones of voice and rhythms, but with my eyes I see words and sentences. » (Je n’entends pas la langue, j’entends des tonalités et des rythmes, mais avec mes yeux je vois les mots et les phrases [traduction libre].)

Le rapport à l’image acoustique en sténographie est relativement différent de celui procuré par l’écriture usuelle. En effet, la sténographie, parce qu’elle compresse l’information phonétiquement et avec perte, ne permet pas de limiter ces phases de tâtonnement permettant d’associer un mot à son image acoustique. Lors de la lecture, nombre de sténogrammes ne peuvent être directement associés au mot qu’ils transcrivent ; ils ne sont alors que des agrégats de phonèmes dont on cherche à épuiser les combinatoires lexicologiques. À ce moment, il est impossible de leur associer une image acoustique : il n’y a pas de différence entre le sténogramme et les sons. La sténographie, comme précisé en section I.a.3.ii., n’est pas une technologie de la lecture a contrario de l’écriture usuelle. À ce titre, la sténographie tombe par moments dans la musique ou dans la poésie concrète. La vocalisation de sons dénués de sémantique permet de ne plus considérer la parole simplement comme un vecteur de langage, mais de se la réapproprier comme un outil musical. Certains compositeurs, comme Karlheinz Stockhausen ou Jaap Blonk (1953-), se sont aventurés dans cette direction en essayant de travailler avec la phonétique plutôt qu’avec l’écriture usuelle pour les vocalisations de leurs pièces. Nous reproduisons ici deux de leurs documents (figures 32 et 33). Dans plusieurs de ses documents de travail, Stockhausen eut recours à l’alphabet phonétique international (api) pour gagner en précision dans sa notation et jouer avec les variations de timbre qui résulte des différentes voyelles et consonnes. Jaap Blonk a quant à lui enrichi l’api en développant sa propre extension du système : le blipax, pour BLonks ipa eXtended. Nous noterons que ses choix graphiques comportent de nombreuses qualités sténographiques.
Les possibilités phonétiques prêtées par la sténographie peuvent, si c’est l’objectif que l’on souhaite atteindre, permettre de séparer l’écriture du langage. Ainsi, la sténographie peut être utilisée à des fins purement phonétiques, et constituer une alternative sérieuse à l’api, basée sur des caractères souvent complexes et peu optimisés graphiquement.


2. Pour la notation musicale

Dans la section I.c.2, nous avons fait remarquer que la sténographie musicale avait toujours essayé de transcrire uniquement la musique savante, en maintenant comme volonté principale de dépasser la vitesse de scripturalisation du système solfégique. La réputation actuelle de la sténographie musicale, inexistante, dénote de l’échec sur lequel aboutirent ces indénombrables entreprises. Dans cette dernière section, nous tenterons de développer des angles d’approche alternatifs à ceux des sténographes-inventeurs du xixe siècle. Pour ce faire, nous repartirons des points abordés au début de la seconde partie, à savoir les innovations conceptuelles du xxe et xxie siècle dans la notation musicale et le contexte technologique du début des années 2020. Nous verrons en quoi un équivalent sténographique du système solfégique n’est pas la seule option disponible pour une application de la sténographie en musique, et qu’elle peut justement venir en appoint au système dominant, là où il présente des faiblesses. Enfin, nous examinerons quelques possibles applications concrètes de la sténographie au regard de la vision par ordinateur et des interactions humain-machine.

i. La notion de l’esquisse

La sténographie est pensée pour la vitesse, pour l’écriture du présent et de l’évanescent. L’un des objectifs récurrents de la sténographie musicale, au-delà de la scripturalisation en temps réel de la musique, était l’écriture des airs qui traversent le compositeur pendant la durée d’un instant. Cette idée rendre dans le domaine de l’esquisse, un objet dont les contours ne sont pas aussi clairs que la trivialité du mot pourrait laisser entendre. Plusieurs théoriciens se sont intéressés à la notion de l’esquisse, et ont tenté de comprendre ce qui pouvait être considéré comme entrant dans son champ et à l’inverse ce qui n’y appartient pas. Selon Goodman, par exemple, « l’esquisse ne fonctionne pas du tout dans un langage ou une notation, mais dans un système sans différenciation ni syntaxique ni sémantique. » C’est-à-dire que l’esquisse serait un entre-deux du dessin et du système, où les règles se plient à la volonté du moment pour accueillir l’expressivité du geste. L’esquisse peut intégrer des systèmes, comme lorsqu’un compositeur dessine à la va-vite une portée sur le coin d’une page, mais reste flexible ; elle est une étape intermédiaire à la création, ne se veut pas définitive. Une esquisse reste ouverte. De même, la sténographie, comme nous l’avons vu, est la plupart du temps vouée à être retranscrite. Lors des retranscriptions, il est possible de reprendre la sémantique. La polysémie de la sténographie peut, dans le cadre d’une esquisse, trouver son intérêt : étant donné qu’elle se veut ouverte, la sténographie laisse un champ de possibilités importants derrière elle. Certains pourraient prendre ces zones troubles comme un manque de maîtrise, d’autres comme un terreau fertile d’inspirations. Billeter dit à propos de la pratique de la musique et de la calligraphie que « l’exécution ne tolère aucun repentir » ; cependant, ce n’est pas vrai dans l’esquisse. L’exécution d’une esquisse invite ces incidents à advenir – elle les provoque même –, et ce, autant en musique qu’en calligraphie.
Dans cette optique, la sténographie, en sa qualité d’art polysémique de la rapidité et d’état intermédiaire, semble d’autant plus adaptée à l’esquisse. Nous pouvons ajouter à ces propriétés la tendance des sténographes de naturellement se doter de nouveaux signes personnels, soit de manière spontanée, soit avec plus de réflexion. Peut-être que ces systèmes auraient plu à Boulez qui développa aussi sa conception de la notion d’esquisse. Il met en particulier l’accent sur la l’aspect inachevé de cette dernière, et la met en contraste avec L’Œuvre ouverte d’Umberto Eco. Il développe aussi le caractère aléatoire de l’esquisse. Chez lui comme chez Cage, l’interprétabilité de ses partitions aurait pu être guidée par des systèmes sténographiques. Ici, la technologie ne servirait donc pas à produire du fini, mais à produire justement une étape intermédiaire accueillant encore des possibilités d’interprétation variées.

ii. Scripturalisation performative de la musique : entre la partition animée et la partition en temps réel

Une autre piste de cas d’utilisation pour la sténographie dans le champ de la musique pourrait se trouver dans un dispositif n’existant pas à notre connaissance. Cette section – très spéculative – vise à dérouler un mode de performance musicale dont les outils logiciels n’existent encore que dans le monde des idées. Nous avons abordé en sections II.a.3.ii. et iii. respectivement les notions de partition en temps réel et de partition animée. Ici, nous tenterons de mettre en commun divers attributs de ces deux types de partitions pour permettre un environnement performatif sur mesure à l’écriture manuscrite de la musique.
La partition en temps réel met en place une boucle de rétroaction entre l’ordinateur, qui génère la partition, et les interprètes. La présence de l’ordinateur est rendue nécessaire pour répondre à deux besoins : le premier est que la partition doit être actualisée en réaction à la musique en train de se faire dans un délai très court, et le second est que cette partition actualisée doit être rendue visible aux interprètes. La vitesse de réaction de l’ordinateur est clé dans cette boucle : celle-ci est négligeable face à la vitesse de réaction des humains. Seulement, il est possible d’améliorer la vitesse de réaction des humains par l’utilisation de systèmes de scripturalisation plus optimisés, comme la sténographie. Ainsi, en remplaçant l’ordinateur par un compositeur-sténographe, il devient possible de reproduire le schéma imaginé par Winkler. La boucle de rétroaction s’effectuerait pas avec l’ordinateur mais avec un performeur additionnel disposant d’un support d’écriture. Les systèmes sténographiques utilisés pourraient être variables, mettre en avant des règles définies au préalable avec les autres performeurs, et s’inscrire dans les notations encadrées de Karkoschka. Concernant le deuxième besoin auquel répond l’ordinateur, à savoir celui de la diffusion de l’image, il serait là nécessaire de mettre en place un moyen de captation. Une possibilité envisageable serait l’InkSplorer de Garcia qui, couplé à un patch Max/msp par exemple, pourrait devenir une interface très intuitive pour diffuser le dessin. Côté logiciel, en plus des divers environnements de programmation, il est aussi possible d’inclure tous les programmes permettant le dessin à main levée – soit tous les logiciels marqués de la lettre m – dans l’hypothèse où l’utilisateur disposerait d’une tablette graphique. Dans le cas de figure que nous décrivons ici, l’ordinateur est toujours impliqué : il sert d’interface permettant la diffusion de la partition aux interprètes. L’ordinateur pourrait aussi servir à la curation des tracés ; il serait peut-être pertinent de laisser à un algorithme la tâche de faire disparaître les plus anciens d’entre eux, par exemple. Par ailleurs, rien n’empêche l’ordinateur de lui aussi interpréter la partition, et donc de disposer d’une couche de synthèse sonore. Ainsi, tous les programmes permettant la synthèse sonore comme ceux ne la permettant pas (respectivement s et ns) sont admissibles.
La partition animée présente quant à elle d’autres points d’intérêts qui nous sont ici utiles. Un des critères de la définition de Hope doit cependant être brisé pour permettre la performativité de la composition et la sténographie de rencontrer son potentiel. Il s’agit de la notion de fixed media (en français support fixe) : une partition animée est toujours finale. Si elle est modifiée, alors il s’agit par définition d’une autre partition animée. Nous ne pensons pas que la sténographie ait un réel intérêt dans la composition à la table, au contraire, étant donné qu’elle s’inscrit dans le présent, elle permet de travailler l’improvisation. Le paradigme qui nous intéresse dans la partition animée pourrait être compatible avec la partition en temps réel, mais nous n’avons pas trouvé d’occurrences de celui-ci dans ces dernières : il s’agit du déroulement de la partition, et la monstration par la barre verticale des signes que les interprètes doivent exécuter. Ce modèle, assez simple à comprendre, permettrait la scripturalisation de sténogrammes sur une forme de tapis roulant virtuel et donc de laisser une marge d’anticipation aux musiciens.
Encore une fois, une proposition notationnelle de ce type ne rentrerait pas dans les notations précises de Karkoschka, mais au mieux dans la catégorie des notations encadrées. Une remarque concernant les systèmes notationnels compatibles avec la présente proposition d’interaction humain-machine : il n’existe pas de liste établie de la multitude de notations existantes, et il ne pourrait pas en exister une exhaustive pouvant circonscrire notre proposition. En effet, bien qu’il y aurait sûrement parmi les sténographies musicales déjà inventées des propositions compatibles avec une scripturalisation performative de la musique, nous ne nous arrêtons pas à celles-ci. Sans oublier de prendre en compte les fréquentes réticences des interprètes lettrés du solfège à apprendre de nouvelles notations, rien n’empêche un compositeur d’élaborer un système faisant preuve de sobriété, ou d’adapter une notation pré-existante. De même, rien n’empêche non plus de penser ce système alors que la performance est en train d’advenir : n’est-ce pas le propre du live coding ? Une seule contrainte demeure : écrire aussi vite que la musique. La notation utilisée n’a pas à être totalisante, ce serait d’ailleurs un écueil à éviter ; elle peut retranscrire tout type de caractéristique, faire passer n’importe quelle indication, mais doit cependant pouvoir le faire dans l’instant présent.

iii. Le potentiel de la vision par ordinateur

La vision par ordinateur, ou en anglais computer vision, est une branche de l’informatique consistant à permettre aux ordinateurs une compréhension sémantique des images qui leur parviennent. Nous avons déjà évoqué dans ce mémoire le sous-domaine de la reconnaissance de caractères, en mettant une emphase sur le fait qu’il est aujourd’hui impossible de transcrire la sténographie en écriture usuelle de manière automatisée. Comme nous l’avons précisé, cette réalité n’est pas due tant à un problème technique qu’à un manque d’intérêt de la communauté scientifique envers la sténographie. La vision par ordinateur pourrait cependant venir apporter des fonctionnalités importantes à la proposition décrite dans la section précédente. En effet, à l’instar du paradigme de la notation en temps réel, la vision par ordinateur pourrait engager des processus de collaboration entre le scripteur et l’ordinateur ; un partenariat au sein de la performance. 
Prenons par l’exemple de l’upic pour illustrer notre propos. La machine de Xenakis aborde le tracé d’une manière purement quantitative : si elle observe à une certaine hauteur de la feuille la présence d’un trait, alors un son d’une fréquence proportionnelle sera produit. La forme du tracé n’influe pas sur autre chose que l’évolution de la fréquence fondamentale du son à travers le temps. Xenakis, lors de son entretien avec Bosseur, note :

« un cercle, c’est une ligne qui se mord la queue, qui se rejoint. Si on veut interpréter cela dans le domaine sonore, on prend la hauteur, qui est la propriété la plus simple, et on dessine un cercle dans ce plan à deux dimensions qui a la hauteur et le temps comme axes. Si vous commencez à un point donné du cercle, vous continuez sur ce cercle en partant du plus bas vers le plus haut, ensuite vous commencez à descendre. Cependant, à un moment donné, vous devez nécessairement commencer à reculer par rapport au temps et, à ce moment-là, ce n’est plus possible. Alors, si on veut obtenir un cercle auditif, ce devra plutôt être quelque chose qui ressemble à une sinusoïde. »

Si Xenakis avait disposé des technologies contemporaines de vision par ordinateur, alors peut-être n’aurait-il pas tenu ce discours. En effet, il est trivial aujourd’hui de faire reconnaître à une machine un cercle. Le « cercle auditif » que mentionne Xenakis n’a plus à être représenté sous la forme d’une sinusoïde, il pourrait simplement être cercle. La vision par ordinateur permet d’ajouter une couche d’interprétation qualitative de l’écriture. Xenakis prit bien sûr pour son exemple une forme de base, universelle, mais ce concept est généralisable à virtuellement toutes sortes de formes, comme les sténogrammes. C’est peut-être en cela que les technologies contemporaines pourraient permettre de revoir le travail de l’upic, comme elles rendirent possible la vision de Xenakis en son temps. Une approche qualitative du tracé n’aurait cependant pas à faire fi de toute considération quantitative de ce dernier : les deux pourraient coexister. Avec le cercle par exemple, il serait envisageable de déduire du tracé qu’il s’agit bien d’un cercle, et donc de le catégoriser comme tel, mais aussi d’en apprécier les irrégularités (personne à part peut-être Giotto n’est capable de tracer parfaitement un cercle à main levée) et de les interpréter, par exemple, dans une synthèse sonore. À l’inverse, si c’est le souhait du compositeur, il serait aussi possible de gommer les irrégularités du tracé en le remplaçant par le cercle correspondant. Bien évidemment, cette catégorisation sémantique pourrait établir une correspondance avec des qualités sonores particulières et propres au système utilisé.
Il nous reste à évoquer une dernière possibilité pour la vision par ordinateur : tirer partie des propriétés de compression de la sténographie. En effet, en prenant pour exemples des systèmes de sténographie musicale comme celui de Baumgartner, basé sur les motifs musicaux, il est possible de compresser les tracés sans perte. Ainsi, on peut imaginer sans mal un logiciel capable de retranscrire dans le système solfégique (ou d’une autre manière) l’information densifiée dans un sténogramme.
Le compositeur JeongHo Park (1968-) semble commencer à expérimenter les applications de la vision par ordinateur dans le champ de la partition animée. Nous sommes confiant en l’idée que nous verrons se développer d’autres initiatives de cet acabit durant les années à venir. Qui sait, peut-être même qu’elles seront propulsées par des systèmes notationnels répondant à la définition de sténographie.


Conclusion

Penser la réhabilitation d’une technologie ayant périclité n’est pas chose aisée. Il s’agit d’admettre ses défauts, mis en avant par le recul historique, mais surtout d’éviter de reproduire d’une manière inattendue – déplacée dans le contexte contemporain – les situations où nous la savons obsolète. C’est là que réside toute la difficulté : comprendre en quoi diffère l’environnement dans lequel nous nous inscrivons, et en déceler les singularités permettant d’opérer une réévaluation favorable.
Voilà ce que nous avons tenté de faire avec ce mémoire dont il reste encore à vérifier toutes les hypothèses par la pratique. Nous avons dans un premier temps pris une approche purement historique et retracé une chronologie de la sténographie de la parole et de la sténographie de la musique. Puis, à la lumière de ce fameux recul historique, nous avons tenté de recontextualiser ces savoirs dans le domaine de la musique électroacoustique contemporaine, avec une approche qui relève finalement de la recherche en interaction homme-machine, et en espérant réussir à poser les bases conceptuelles d’un travail pratique encore naissant. Ce n’est que le début de cette recherche. Nous le mentionnions en introduction, la sténographie représentait pour nous la face émergée d’un iceberg. Aujourd’hui, nous pensons en avoir cartographié une part non négligeable, ou du moins une partie suffisante pour en comprendre les tenants et aboutissants et nous permettre d’en faire un matériau propre à accueillir une expérimentation pratique. Ainsi, il est probable que tout au mieux quelques des hypothèses formulées ici s’avèrent confirmées. Finalement, il s’agira simplement de vérifier si le contexte technologique actuel a bien été interprété, ou non.
Le chantier que nous avons ouvert est titanesque : il nécessitera de faire des choix, comme nous avons fait des choix parmi les sujets qu’il était possible d’aborder dans ce mémoire. Car en effet, la réhabilitation de la sténographie ne saurait se limiter au domaine de la musique. Tout au long de cet écrit, nous avons abordé entre les lignes (ou plutôt en notes de bas de page, pour être précis) les liens qu’entretient la sténographie avec d’autres domaines. Ce mémoire constitue le premier opus, mais d’autres pourraient suivre ; au croisement avec les autres arts, avec la cryptographie et la culture du secret, avec la compression, la pédagogie et la linguistique… Brièvement, voici sujet par sujet une idée des pistes qu’il reste à explorer :
Dans les arts. En dehors de la musique, la sténographie s’est invitée en littérature, chez les philosophes, dans les arts visuels et en danse. En littérature, elle a occupé des écrivains comme Charles Dickens, qui l’utilisait pour certaines de ses premières versions, ou encore Robert Walser et ses « microgrammes ». Fiodor Dostoïevski, quant à lui, dictait parfois ses écrits à des sténographes pour augmenter son débit d’écriture. Des philosophes l’utilisaient exclusivement, comme Husserl qui faisaient ensuite transcrire ses sténographies à ses assistants ; ou Locke, qui se trouva être un fervent défenseur de la sténographie pour un usage en rhétorique et dans les études. À l’instar de la tentative de Friedrich Kittler, dans son ouvrage Gramophone, Film, Typewriter, de comprendre comment le passage de l’écriture manuscrite à la machine à écrire a influencé le contenu des textes, il serait intéressant de voir comment la sténographie influence les auteurs lorsque ceux-ci l’utilisent en tant qu’écriture personnelle. En peinture, la sténographie a là encore trouvé des adeptes. Celui dont l’usage des sténogrammes est le plus connu et le plus récurrent est sans conteste Paul Klee, qui utilisait des formes de sténographies personnelles dans ses tableaux. De même, la sténographie piqua l’intérêt de Jackson Pollock, qui y consacra une toile en 1942 avec Stenographic Figure (figure 34). Entre l’esquisse et le système, entre le dessin et le langage, l’expressionnisme a échangé quelques passes avec la sténographie, méritant ainsi qu’on s’y arrête plus longuement. Avec le mouvement Dada, on retrouve des écrits d’artistes transcrits en sténographie, notamment ceux de Kurt Schwitters qui avait uniquement recours au système Gabelsberger. Enfin, en danse, le seul art en plus de la musique pour lequel il existe des systèmes notationnels, la sténographie ne manque pas de trouver des applications. Premièrement, dans le rapport au mouvement : en danse, comme en calligraphie ou en sténographie, le rapport au corps est central. de même, il existe des manières d’abréger, en quelque sorte, une chorégraphie. Billeter nous invite à réfléchir sur le lien unissant la danse à la calligraphie au travers du concept d’ellipse (figure 35) – un mécanisme abréviatif, donc. Il note :

« Je me souviens d’un vieillard qui dansait la sardane un soir dans un port catalan. Alors que les autres danseurs, dans les parties rapides, détaillaient le pas, lui se contentait de temps à autre de l’ébaucher ou, plutôt, d’en donner l’épure. Il résumait d’un geste enveloppant de la jambe sept ou huit sauts vifs de ses compagnons. L’aisance divine de ces ellipses, que le contraste avec l’entrain de la musique rendait plus frappante encore, est restée gravée dans ma mémoire. »

Deuxièmement, dans la scripturalisation de la danse : il existe aussi bien des systèmes sténographiques appliqués à la gymnastique que d’autres notations, plus personnelles, comme celle de l’artiste contemporain Alexandre Bavard et son Bulky System. Comme nous l’avons défini, la sténographie ne se limite pas à l’écriture des phénomènes sonores : elle pourrait aussi bien transcrire le chant des oiseaux que les fluctuations du vent.
En cryptographie. Nonobstant un usage erroné du terme stéganographie à la place de sténographie et inversement, nous avons vu tout au long de ce mémoire que cette confusion n’était pas complètement fortuite. La sténographie a régulièrement été perçue comme un art occulte au fil des âges, et cette réputation l’a poursuivie jusqu’à encore aujourd’hui, où des personnes s’étonnent de voir nos (l’auteur) textes sténographiques, cryptiques, rédigés lors de phases de prises de note. Nous l’avons constaté nous-même dans notre pratique de la sténographie : il y a un sentiment étrange qui survient lorsque l’on écrit dans un système qui n’est pas maîtrisé par beaucoup. Il s’agit d’une sorte de rapport au secret, qui fut la raison pour laquelle Samuel Pepys, le diariste anglais du xviie siècle, se permit de tenir des propos aussi relâchés dans ses notes, et que les transcriptions de ses écrits continuent de se vendre même à notre époque. Pepys utilisait un système conventionnel, la tachygraphy de Thomas Shelton, mais beaucoup de sténographes intégraient rapidement leurs propres abréviations idiosyncratiques. C’était le cas d’Husserl, mais aussi des scribes du Moyen Âge. À partir de quel stade peut-on considérer un signe comme étant conventionnel ? Est-ce que l’écriture doit toujours être utilisée pour la communication, pour transcrire ce qui se dit ? Être déchiffrable ? Selon Barthes, il n’existe aucune différence entre une écriture indéchiffrée et une autre indéchiffrable :

« Or, l’intéressant – le stupéfiant –, c’est que rien, absolument rien, ne distingue ces écritures vraies et ces écritures fausses : aucune différence, sinon de contexte, entre l’indéchiffré et l’indéchiffrable. C’est nous, notre culture, notre loi, qui décidons du statut référent d’une écriture. Cela veut dire quoi ? Que le signifiant est libre, souverain. Une écriture n’a pas besoin d’être “lisible” pour être pleinement une écriture. »

Quid des sténographies personnelles ? Tout un pan de la sténographie, relevant de la cryptographie, pourrait aussi bien trouver des applications que nécessiter de s’y attarder. Dans cette continuité, un autre aparté doit être fait sur la notion de compression.
En compression de données. Nous l’avons évoqué brièvement déjà, la sténographie est aussi une technologie de la compression ; cette propriété vient du terme « abréviatif » compris dans sa définition. Il est cependant à noter qu’aujourd’hui, la notion de compression de données est presque exclusivement associée à l’informatique. Pourtant, on compresse l’information depuis aussi longtemps qu’on écrit. Tous les systèmes de numération sont basés sur ce principe. Il est plus efficace d’écrire le nombre n devant un caractère plutôt que d’écrire n fois ce même caractère. La sténographie, comme les systèmes de numération, font partie des technologies de la compression qu’il nous est possible d’assimiler mentalement et d’utiliser par nous-mêmes, sans externaliser ce travail grâce à une machine. La compression représente un enjeu technologique majeur du xxie siècle : il s’agit d’un outil clé pour limiter les dépenses énergétiques liées au numérique. À l’échelle personnelle, la sténographie peut constituer une forme d’écologie de soi, permettre non pas de compresser afin d’emmagasiner plus, mais de compresser pour emmagasiner assez. La sténographie répond à une limite physique claire : notre vitesse d’écriture. Elle nous force ainsi à faire des choix et à transcrire seulement le plus essentiel.
En pédagogie et en linguistique. Dernièrement, nous souhaitons mettre l’accent sur deux domaines que nous avons davantage développés dans ce mémoire que ceux cités plus haut. Ceux-ci ont une place à part car ils étaient déjà centraux dans la rhétorique des sténographes du xixe siècle, et nous avons montré où ces arguments les ont menés. Les questions de l’orthographe du français moderne ont fait couler beaucoup d’encre depuis la création de l’organisme de normalisation de la langue française, à savoir l’Académie française. Certaines des règles de la langue de Molière ne trouvent leurs fondements que dans des stratagèmes d’élitisation ; mécaniquement, certains en payent le prix. Les principaux arguments de Pitman et de Duployé consistaient en une simplification de l’orthographe et de la grammaire, et c’est vrai : la sténographie facilite énormément l’écriture du français. Attention, nous ne nous lançons pas ici dans une approche prescriptiviste de l’écriture – que ce soit du français ou de la musique – mais nous pensons qu’étudier la sténographie sous ce prisme-là peut se réveler, encore aujourd’hui, plein d’enrichissements. Dans la pédagogie par exemple, comme nous avons pu commencer à le développer en section II.b.1.i. La pédagogie et le jeu, la sténographie présente un certain nombre de qualités, et nous espérons continuer d’en découvrir dans le futur.
Ces champs de recherches, divers et variés, témoignent de la richesse des thématiques qui gravitent autour de la sténographie. Bien qu’elle semble aujourd’hui anachronique et sur le point de s’éteindre, peut-être que la disparition des dernières sténo-dactylographe ne marquera pas la fin de l’histoire de la sténographie. L’écriture, et par extension la sténographie, est une exaptation du cerveau humain indépendante de tout outillage ou presque, contrairement à l’économie du numérique, basée sur des industries lourdes. Ces systèmes sont bien réapparus de nulle part avec Willis au xviie siècle, rien n’indique donc qu’un ensevelissement total de la sténographie demain serait définitif. Nous verrons bien.


Remerciements

C’était bien de faire ce travail. C’était intense aussi. Heureusement qu’on a pas à le faire tout seul ; c’est le faire entouré qui rend l’exercice intéressant.
Il est d’usage de commencer la page de remerciements d’un mémoire en mentionnant la personne chargée de suivre le projet de recherche de l’étudiant, que celle-ci ait été présente ou non auprès de ce dernier. Je dois bien avouer que ce n’est pas l’étiquette qui m’amène à chaleureusement remercier Pascal Rousseau. M. Pascal Rousseau s’est montré à l’écoute, extrêmement disponible, et a su m’orienter avec brio dans ce projet. C’était un réel plaisir que d’avoir pu développer ma recherche sous sa direction. Pour toute son expérience et ses conseils, je lui exprime ma reconnaissance.
Il ne fut pas seul à m’encadrer dans ce travail ; Vincent Rioux m’a lui aussi fait part de précieuses pistes qui se montrèrent plus que décisives bien que je me sois manifesté tard auprès de lui. Il a toute ma gratitude.
Merci maintenant à Manon Fafin et Danielle Orhan, fabuleuses relectrices, qui apportèrent rigueur et justesse à ma prose et à mon orthographe ; elle en avait bien besoin.
Je tiens aussi à remercier toutes les personnes qui m’auront accompagné dans mes réflexions et auront pris le temps de se laisser emmener dans mes digressions sténographiques. Professeurs et professeures, amis et amies, camarades d’atelier et de bibliothèque, consciemment ou non, chacune d’entre elles a écrit une partie de cette étude. C’est ces discussions qui donnent une âme à ce travail.

Enfin, je dédie ce mémoire à ma mère, Isabelle Trividic, pour tout le courage et toute la force dont elle fait preuve chaque jour malgré les épreuves. Merci pour tout.